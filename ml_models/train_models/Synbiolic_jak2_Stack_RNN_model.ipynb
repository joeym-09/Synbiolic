{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Synbiolic jak2 - Stack RNN model.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "machine_shape": "hm"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "code",
      "metadata": {
        "id": "nS8DgoDpXQbb",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "outputId": "0d58b99b-2585-416f-ff83-cc8345c65ebc"
      },
      "source": [
        "#Install deepchem + rdkit \n",
        "!wget -c https://repo.continuum.io/miniconda/Miniconda3-latest-Linux-x86_64.sh\n",
        "!chmod +x Miniconda3-latest-Linux-x86_64.sh\n",
        "!time bash ./Miniconda3-latest-Linux-x86_64.sh -b -f -p /usr/local\n",
        "!conda install -y -c deepchem -c rdkit -c conda-forge -c omnia deepchem-gpu=2.1.0 python=3.6"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "--2020-03-18 17:00:59--  https://repo.continuum.io/miniconda/Miniconda3-latest-Linux-x86_64.sh\n",
            "Resolving repo.continuum.io (repo.continuum.io)... 104.18.201.79, 104.18.200.79, 2606:4700::6812:c94f, ...\n",
            "Connecting to repo.continuum.io (repo.continuum.io)|104.18.201.79|:443... connected.\n",
            "HTTP request sent, awaiting response... 200 OK\n",
            "Length: 85055499 (81M) [application/x-sh]\n",
            "Saving to: ‘Miniconda3-latest-Linux-x86_64.sh’\n",
            "\n",
            "Miniconda3-latest-L 100%[===================>]  81.12M  89.7MB/s    in 0.9s    \n",
            "\n",
            "2020-03-18 17:01:00 (89.7 MB/s) - ‘Miniconda3-latest-Linux-x86_64.sh’ saved [85055499/85055499]\n",
            "\n",
            "PREFIX=/usr/local\n",
            "Unpacking payload ...\n",
            "Collecting package metadata (current_repodata.json): - \b\b\\ \b\b| \b\b/ \b\bdone\n",
            "Solving environment: \\ \b\b| \b\bdone\n",
            "\n",
            "## Package Plan ##\n",
            "\n",
            "  environment location: /usr/local\n",
            "\n",
            "  added / updated specs:\n",
            "    - _libgcc_mutex==0.1=main\n",
            "    - asn1crypto==1.3.0=py37_0\n",
            "    - ca-certificates==2020.1.1=0\n",
            "    - certifi==2019.11.28=py37_0\n",
            "    - cffi==1.14.0=py37h2e261b9_0\n",
            "    - chardet==3.0.4=py37_1003\n",
            "    - conda-package-handling==1.6.0=py37h7b6447c_0\n",
            "    - conda==4.8.2=py37_0\n",
            "    - cryptography==2.8=py37h1ba5d50_0\n",
            "    - idna==2.8=py37_0\n",
            "    - ld_impl_linux-64==2.33.1=h53a641e_7\n",
            "    - libedit==3.1.20181209=hc058e9b_0\n",
            "    - libffi==3.2.1=hd88cf55_4\n",
            "    - libgcc-ng==9.1.0=hdf63c60_0\n",
            "    - libstdcxx-ng==9.1.0=hdf63c60_0\n",
            "    - ncurses==6.2=he6710b0_0\n",
            "    - openssl==1.1.1d=h7b6447c_4\n",
            "    - pip==20.0.2=py37_1\n",
            "    - pycosat==0.6.3=py37h7b6447c_0\n",
            "    - pycparser==2.19=py37_0\n",
            "    - pyopenssl==19.1.0=py37_0\n",
            "    - pysocks==1.7.1=py37_0\n",
            "    - python==3.7.6=h0371630_2\n",
            "    - readline==7.0=h7b6447c_5\n",
            "    - requests==2.22.0=py37_1\n",
            "    - ruamel_yaml==0.15.87=py37h7b6447c_0\n",
            "    - setuptools==45.2.0=py37_0\n",
            "    - six==1.14.0=py37_0\n",
            "    - sqlite==3.31.1=h7b6447c_0\n",
            "    - tk==8.6.8=hbc83047_0\n",
            "    - tqdm==4.42.1=py_0\n",
            "    - urllib3==1.25.8=py37_0\n",
            "    - wheel==0.34.2=py37_0\n",
            "    - xz==5.2.4=h14c3975_4\n",
            "    - yaml==0.1.7=had09818_2\n",
            "    - zlib==1.2.11=h7b6447c_3\n",
            "\n",
            "\n",
            "The following NEW packages will be INSTALLED:\n",
            "\n",
            "  _libgcc_mutex      pkgs/main/linux-64::_libgcc_mutex-0.1-main\n",
            "  asn1crypto         pkgs/main/linux-64::asn1crypto-1.3.0-py37_0\n",
            "  ca-certificates    pkgs/main/linux-64::ca-certificates-2020.1.1-0\n",
            "  certifi            pkgs/main/linux-64::certifi-2019.11.28-py37_0\n",
            "  cffi               pkgs/main/linux-64::cffi-1.14.0-py37h2e261b9_0\n",
            "  chardet            pkgs/main/linux-64::chardet-3.0.4-py37_1003\n",
            "  conda              pkgs/main/linux-64::conda-4.8.2-py37_0\n",
            "  conda-package-han~ pkgs/main/linux-64::conda-package-handling-1.6.0-py37h7b6447c_0\n",
            "  cryptography       pkgs/main/linux-64::cryptography-2.8-py37h1ba5d50_0\n",
            "  idna               pkgs/main/linux-64::idna-2.8-py37_0\n",
            "  ld_impl_linux-64   pkgs/main/linux-64::ld_impl_linux-64-2.33.1-h53a641e_7\n",
            "  libedit            pkgs/main/linux-64::libedit-3.1.20181209-hc058e9b_0\n",
            "  libffi             pkgs/main/linux-64::libffi-3.2.1-hd88cf55_4\n",
            "  libgcc-ng          pkgs/main/linux-64::libgcc-ng-9.1.0-hdf63c60_0\n",
            "  libstdcxx-ng       pkgs/main/linux-64::libstdcxx-ng-9.1.0-hdf63c60_0\n",
            "  ncurses            pkgs/main/linux-64::ncurses-6.2-he6710b0_0\n",
            "  openssl            pkgs/main/linux-64::openssl-1.1.1d-h7b6447c_4\n",
            "  pip                pkgs/main/linux-64::pip-20.0.2-py37_1\n",
            "  pycosat            pkgs/main/linux-64::pycosat-0.6.3-py37h7b6447c_0\n",
            "  pycparser          pkgs/main/linux-64::pycparser-2.19-py37_0\n",
            "  pyopenssl          pkgs/main/linux-64::pyopenssl-19.1.0-py37_0\n",
            "  pysocks            pkgs/main/linux-64::pysocks-1.7.1-py37_0\n",
            "  python             pkgs/main/linux-64::python-3.7.6-h0371630_2\n",
            "  readline           pkgs/main/linux-64::readline-7.0-h7b6447c_5\n",
            "  requests           pkgs/main/linux-64::requests-2.22.0-py37_1\n",
            "  ruamel_yaml        pkgs/main/linux-64::ruamel_yaml-0.15.87-py37h7b6447c_0\n",
            "  setuptools         pkgs/main/linux-64::setuptools-45.2.0-py37_0\n",
            "  six                pkgs/main/linux-64::six-1.14.0-py37_0\n",
            "  sqlite             pkgs/main/linux-64::sqlite-3.31.1-h7b6447c_0\n",
            "  tk                 pkgs/main/linux-64::tk-8.6.8-hbc83047_0\n",
            "  tqdm               pkgs/main/noarch::tqdm-4.42.1-py_0\n",
            "  urllib3            pkgs/main/linux-64::urllib3-1.25.8-py37_0\n",
            "  wheel              pkgs/main/linux-64::wheel-0.34.2-py37_0\n",
            "  xz                 pkgs/main/linux-64::xz-5.2.4-h14c3975_4\n",
            "  yaml               pkgs/main/linux-64::yaml-0.1.7-had09818_2\n",
            "  zlib               pkgs/main/linux-64::zlib-1.2.11-h7b6447c_3\n",
            "\n",
            "\n",
            "Preparing transaction: - \b\b\\ \b\b| \b\b/ \b\bdone\n",
            "Executing transaction: \\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\bdone\n",
            "installation finished.\n",
            "WARNING:\n",
            "    You currently have a PYTHONPATH environment variable set. This may cause\n",
            "    unexpected behavior when running the Python interpreter in Miniconda3.\n",
            "    For best results, please verify that your PYTHONPATH only points to\n",
            "    directories of packages that are compatible with the Python interpreter\n",
            "    in Miniconda3: /usr/local\n",
            "\n",
            "real\t0m23.207s\n",
            "user\t0m7.541s\n",
            "sys\t0m3.952s\n",
            "Collecting package metadata (current_repodata.json): - \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\bdone\n",
            "Solving environment: | \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\bfailed with initial frozen solve. Retrying with flexible solve.\n",
            "Solving environment: - \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\bfailed with repodata from current_repodata.json, will retry with next repodata source.\n",
            "Collecting package metadata (repodata.json): \\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\bdone\n",
            "Solving environment: \\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\bdone\n",
            "\n",
            "\n",
            "==> WARNING: A newer version of conda exists. <==\n",
            "  current version: 4.8.2\n",
            "  latest version: 4.8.3\n",
            "\n",
            "Please update conda by running\n",
            "\n",
            "    $ conda update -n base -c defaults conda\n",
            "\n",
            "\n",
            "\n",
            "## Package Plan ##\n",
            "\n",
            "  environment location: /usr/local\n",
            "\n",
            "  added / updated specs:\n",
            "    - deepchem-gpu=2.1.0\n",
            "    - python=3.6\n",
            "\n",
            "\n",
            "The following packages will be downloaded:\n",
            "\n",
            "    package                    |            build\n",
            "    ---------------------------|-----------------\n",
            "    absl-py-0.9.0              |           py36_0         162 KB  conda-forge\n",
            "    asn1crypto-1.3.0           |           py36_0         159 KB  conda-forge\n",
            "    astor-0.7.1                |             py_0          22 KB  conda-forge\n",
            "    attrs-19.3.0               |             py_0          35 KB  conda-forge\n",
            "    backcall-0.1.0             |             py_0          13 KB  conda-forge\n",
            "    blas-1.0                   |              mkl           6 KB\n",
            "    bleach-1.5.0               |           py36_0          23 KB  conda-forge\n",
            "    blosc-1.17.1               |       he1b5a44_0         886 KB  conda-forge\n",
            "    boost-1.63.0               |   py36h415b752_1        11.8 MB  rdkit\n",
            "    bzip2-1.0.8                |       h516909a_2         396 KB  conda-forge\n",
            "    c-ares-1.15.0              |    h516909a_1001         100 KB  conda-forge\n",
            "    ca-certificates-2019.11.28 |       hecc5488_0         145 KB  conda-forge\n",
            "    cairo-1.14.12              |       he56eebe_3         1.3 MB  conda-forge\n",
            "    certifi-2019.11.28         |   py36h9f0ad1d_1         149 KB  conda-forge\n",
            "    cffi-1.14.0                |   py36hd463f26_0         221 KB  conda-forge\n",
            "    chardet-3.0.4              |py36h9f0ad1d_1006         188 KB  conda-forge\n",
            "    conda-4.8.3                |   py36h9f0ad1d_1         3.0 MB  conda-forge\n",
            "    conda-package-handling-1.6.0|   py36h8c4c3a4_2         947 KB  conda-forge\n",
            "    cryptography-2.5           |   py36hb7f436b_1         645 KB  conda-forge\n",
            "    cudatoolkit-9.0            |       h13b8566_0       237.0 MB\n",
            "    cudnn-7.6.5                |        cuda9.0_0       143.3 MB\n",
            "    cupti-9.0.176              |                0         1.4 MB\n",
            "    cycler-0.10.0              |             py_2           9 KB  conda-forge\n",
            "    cython-0.29.15             |   py36h831f99a_1         2.2 MB  conda-forge\n",
            "    dbus-1.13.0                |    h4e0c4b3_1000         558 KB  conda-forge\n",
            "    decorator-4.4.2            |             py_0          11 KB  conda-forge\n",
            "    deepchem-gpu-2.1.0         |           py36_0         1.9 MB  deepchem\n",
            "    defusedxml-0.6.0           |             py_0          22 KB  conda-forge\n",
            "    entrypoints-0.3            |py36h9f0ad1d_1001          12 KB  conda-forge\n",
            "    expat-2.2.9                |       he1b5a44_2         191 KB  conda-forge\n",
            "    fftw3f-3.3.4               |                2         1.2 MB  omnia\n",
            "    fontconfig-2.13.0          |       hd36ec8e_5         284 KB  conda-forge\n",
            "    freetype-2.8.1             |       hfa320df_1         789 KB  conda-forge\n",
            "    gast-0.3.3                 |             py_0          12 KB  conda-forge\n",
            "    gettext-0.19.8.1           |    hc5be6a0_1002         3.6 MB  conda-forge\n",
            "    glib-2.55.0                |       h464dc38_2         6.1 MB  conda-forge\n",
            "    grpcio-1.16.0              |py36h4f00d22_1000         1.0 MB  conda-forge\n",
            "    gst-plugins-base-1.12.5    |    h3865690_1000         4.9 MB  conda-forge\n",
            "    gstreamer-1.12.5           |       h61a6719_0         2.1 MB  conda-forge\n",
            "    hdf5-1.10.5                |nompi_h3c11f04_1104         3.1 MB  conda-forge\n",
            "    html5lib-0.9999999         |           py36_0         181 KB  conda-forge\n",
            "    icu-58.2                   |    hf484d3e_1000        22.6 MB  conda-forge\n",
            "    idna-2.6                   |           py36_1         122 KB  conda-forge\n",
            "    importlib-metadata-1.5.0   |   py36h9f0ad1d_1          42 KB  conda-forge\n",
            "    importlib_metadata-1.5.0   |                1           3 KB  conda-forge\n",
            "    intel-openmp-2019.4        |              243         729 KB\n",
            "    ipykernel-5.1.4            |   py36h5ca1d4c_0         160 KB  conda-forge\n",
            "    ipython-7.13.0             |   py36h95af2a2_1         1.1 MB  conda-forge\n",
            "    ipython_genutils-0.2.0     |             py_1          21 KB  conda-forge\n",
            "    ipywidgets-7.5.1           |             py_0         101 KB  conda-forge\n",
            "    jedi-0.16.0                |   py36h9f0ad1d_1         774 KB  conda-forge\n",
            "    jinja2-2.11.1              |             py_0          94 KB  conda-forge\n",
            "    joblib-0.11                |           py36_0         193 KB  conda-forge\n",
            "    jpeg-9c                    |    h14c3975_1001         251 KB  conda-forge\n",
            "    jsonschema-3.2.0           |   py36h9f0ad1d_1          89 KB  conda-forge\n",
            "    jupyter-1.0.0              |             py_2           4 KB  conda-forge\n",
            "    jupyter_client-6.0.0       |             py_0          71 KB  conda-forge\n",
            "    jupyter_console-6.1.0      |             py_1          21 KB  conda-forge\n",
            "    jupyter_core-4.6.3         |   py36h9f0ad1d_1          71 KB  conda-forge\n",
            "    kiwisolver-1.1.0           |   py36hdb11119_1          86 KB  conda-forge\n",
            "    libgfortran-ng-7.3.0       |       hdf63c60_5         1.7 MB  conda-forge\n",
            "    libiconv-1.15              |    h516909a_1005         2.0 MB  conda-forge\n",
            "    libpng-1.6.37              |       hed695b0_0         343 KB  conda-forge\n",
            "    libprotobuf-3.11.3         |       h8b12597_0         4.8 MB  conda-forge\n",
            "    libsodium-1.0.17           |       h516909a_0         330 KB  conda-forge\n",
            "    libtiff-4.0.9              |    h648cc4a_1002         566 KB  conda-forge\n",
            "    libuuid-2.32.1             |    h14c3975_1000          26 KB  conda-forge\n",
            "    libxcb-1.13                |    h14c3975_1002         396 KB  conda-forge\n",
            "    libxml2-2.9.9              |       h13577e0_2         1.3 MB  conda-forge\n",
            "    lzo-2.10                   |    h14c3975_1000         319 KB  conda-forge\n",
            "    markdown-3.2.1             |             py_0          61 KB  conda-forge\n",
            "    markupsafe-1.1.1           |   py36h8c4c3a4_1          26 KB  conda-forge\n",
            "    matplotlib-2.2.2           |   py36h0e671d2_0         4.8 MB\n",
            "    mdtraj-1.9.1               |           py36_1         5.9 MB  deepchem\n",
            "    mistune-0.8.4              |py36h516909a_1000          53 KB  conda-forge\n",
            "    mkl-2018.0.3               |                1       126.9 MB\n",
            "    mkl_fft-1.0.10             |           py36_0         650 KB  conda-forge\n",
            "    mkl_random-1.0.2           |           py36_0         1.3 MB  conda-forge\n",
            "    mock-3.0.5                 |   py36h9f0ad1d_1          44 KB  conda-forge\n",
            "    nbconvert-5.6.1            |           py36_0         467 KB  conda-forge\n",
            "    nbformat-5.0.4             |             py_0          98 KB  conda-forge\n",
            "    networkx-2.1               |             py_1         1.1 MB  conda-forge\n",
            "    notebook-6.0.3             |           py36_0         6.2 MB  conda-forge\n",
            "    numexpr-2.7.1              |   py36hb3f55d8_0         196 KB  conda-forge\n",
            "    numpy-1.15.4               |   py36h1d66e8a_0          34 KB\n",
            "    numpy-base-1.15.4          |   py36h81de0dd_0         3.4 MB\n",
            "    olefile-0.46               |             py_0          31 KB  conda-forge\n",
            "    openmm-7.4.1               |py36_cuda101_rc_1        11.9 MB  omnia\n",
            "    openssl-1.0.2u             |       h516909a_0         3.2 MB  conda-forge\n",
            "    pandas-0.22.0              |           py36_1        26.1 MB  conda-forge\n",
            "    pandoc-2.9.2               |                0        16.8 MB  conda-forge\n",
            "    pandocfilters-1.4.2        |             py_1           9 KB  conda-forge\n",
            "    parso-0.6.2                |             py_0          66 KB  conda-forge\n",
            "    pcre-8.44                  |       he1b5a44_0         261 KB  conda-forge\n",
            "    pdbfixer-1.4               |           py36_0         187 KB  omnia\n",
            "    pexpect-4.8.0              |   py36h9f0ad1d_1          79 KB  conda-forge\n",
            "    pickleshare-0.7.5          |py36h9f0ad1d_1001          13 KB  conda-forge\n",
            "    pillow-5.0.0               |           py36_0         975 KB  conda-forge\n",
            "    pip-20.0.2                 |             py_2         1.0 MB  conda-forge\n",
            "    pixman-0.34.0              |    h14c3975_1003         595 KB  conda-forge\n",
            "    prometheus_client-0.7.1    |             py_0          38 KB  conda-forge\n",
            "    prompt-toolkit-3.0.4       |             py_0         233 KB  conda-forge\n",
            "    prompt_toolkit-3.0.4       |                0           4 KB  conda-forge\n",
            "    protobuf-3.11.3            |   py36he1b5a44_0         696 KB  conda-forge\n",
            "    pthread-stubs-0.4          |    h14c3975_1001           5 KB  conda-forge\n",
            "    ptyprocess-0.6.0           |          py_1001          15 KB  conda-forge\n",
            "    pycosat-0.6.3              |py36h8c4c3a4_1004         107 KB  conda-forge\n",
            "    pycparser-2.20             |             py_0          89 KB  conda-forge\n",
            "    pygments-2.6.1             |             py_0         683 KB  conda-forge\n",
            "    pyopenssl-19.0.0           |           py36_0          81 KB  conda-forge\n",
            "    pyparsing-2.4.6            |             py_0          59 KB  conda-forge\n",
            "    pyqt-5.6.0                 |py36h13b7fb3_1008         5.4 MB  conda-forge\n",
            "    pyrsistent-0.15.7          |   py36h8c4c3a4_1          89 KB  conda-forge\n",
            "    pysocks-1.7.1              |   py36h9f0ad1d_1          27 KB  conda-forge\n",
            "    pytables-3.6.1             |   py36h9f153d1_1         1.5 MB  conda-forge\n",
            "    python-3.6.6               |    hd21baee_1003        29.0 MB  conda-forge\n",
            "    python-dateutil-2.8.1      |             py_0         220 KB  conda-forge\n",
            "    python_abi-3.6             |          1_cp36m           4 KB  conda-forge\n",
            "    pytz-2019.3                |             py_0         237 KB  conda-forge\n",
            "    pyzmq-19.0.0               |   py36h9947dbf_1         503 KB  conda-forge\n",
            "    qt-5.6.2                   |      hd25b39d_14        34.8 MB\n",
            "    qtconsole-4.7.1            |             py_0          87 KB  conda-forge\n",
            "    qtpy-1.9.0                 |             py_0          34 KB  conda-forge\n",
            "    rdkit-2017.09.1            |           py36_1        19.7 MB  rdkit\n",
            "    requests-2.18.4            |           py36_1          91 KB  conda-forge\n",
            "    ruamel_yaml-0.15.71        |py36h14c3975_1000         257 KB  conda-forge\n",
            "    scikit-learn-0.19.1        |   py36hedc7406_0         3.9 MB\n",
            "    scipy-1.1.0                |   py36hfa4b5c9_1        13.2 MB\n",
            "    send2trash-1.5.0           |             py_0          12 KB  conda-forge\n",
            "    setuptools-46.0.0          |   py36h9f0ad1d_2         638 KB  conda-forge\n",
            "    simdna-0.4.2               |             py_0         627 KB  deepchem\n",
            "    sip-4.18.1                 |py36hf484d3e_1000         277 KB  conda-forge\n",
            "    six-1.14.0                 |             py_1          13 KB  conda-forge\n",
            "    tbb-2020.1                 |       hc9558a2_0         1.4 MB  conda-forge\n",
            "    tbb4py-2020.1              |   py36hc9558a2_0         245 KB  conda-forge\n",
            "    tensorboard-1.6.0          |           py36_0         2.9 MB  conda-forge\n",
            "    tensorflow-gpu-1.6.0       |                0           4 KB\n",
            "    tensorflow-gpu-base-1.6.0  |   py36hcdda91b_1        68.1 MB\n",
            "    termcolor-1.1.0            |             py_2           6 KB  conda-forge\n",
            "    terminado-0.8.3            |   py36h9f0ad1d_1          23 KB  conda-forge\n",
            "    testpath-0.4.4             |             py_0          85 KB  conda-forge\n",
            "    tornado-6.0.4              |   py36h8c4c3a4_1         639 KB  conda-forge\n",
            "    traitlets-4.3.3            |   py36h9f0ad1d_1         133 KB  conda-forge\n",
            "    urllib3-1.22               |           py36_0         154 KB  conda-forge\n",
            "    wcwidth-0.1.8              |             py_0          19 KB  conda-forge\n",
            "    webencodings-0.5.1         |             py_1          12 KB  conda-forge\n",
            "    werkzeug-1.0.0             |             py_0         238 KB  conda-forge\n",
            "    wheel-0.34.2               |             py_1          24 KB  conda-forge\n",
            "    widgetsnbextension-3.5.1   |           py36_0         1.8 MB  conda-forge\n",
            "    xgboost-0.6a2              |           py36_2         1.1 MB  conda-forge\n",
            "    xorg-kbproto-1.0.7         |    h14c3975_1002          26 KB  conda-forge\n",
            "    xorg-libice-1.0.10         |       h516909a_0          57 KB  conda-forge\n",
            "    xorg-libsm-1.2.3           |    h84519dc_1000          25 KB  conda-forge\n",
            "    xorg-libx11-1.6.9          |       h516909a_0         918 KB  conda-forge\n",
            "    xorg-libxau-1.0.9          |       h14c3975_0          13 KB  conda-forge\n",
            "    xorg-libxdmcp-1.1.3        |       h516909a_0          18 KB  conda-forge\n",
            "    xorg-libxext-1.3.4         |       h516909a_0          51 KB  conda-forge\n",
            "    xorg-libxrender-0.9.10     |    h516909a_1002          31 KB  conda-forge\n",
            "    xorg-renderproto-0.11.1    |    h14c3975_1002           8 KB  conda-forge\n",
            "    xorg-xextproto-7.3.0       |    h14c3975_1002          27 KB  conda-forge\n",
            "    xorg-xproto-7.0.31         |    h14c3975_1007          72 KB  conda-forge\n",
            "    zeromq-4.3.2               |       he1b5a44_2         668 KB  conda-forge\n",
            "    zipp-3.1.0                 |             py_0          10 KB  conda-forge\n",
            "    ------------------------------------------------------------\n",
            "                                           Total:       871.6 MB\n",
            "\n",
            "The following NEW packages will be INSTALLED:\n",
            "\n",
            "  absl-py            conda-forge/linux-64::absl-py-0.9.0-py36_0\n",
            "  astor              conda-forge/noarch::astor-0.7.1-py_0\n",
            "  attrs              conda-forge/noarch::attrs-19.3.0-py_0\n",
            "  backcall           conda-forge/noarch::backcall-0.1.0-py_0\n",
            "  blas               pkgs/main/linux-64::blas-1.0-mkl\n",
            "  bleach             conda-forge/linux-64::bleach-1.5.0-py36_0\n",
            "  blosc              conda-forge/linux-64::blosc-1.17.1-he1b5a44_0\n",
            "  boost              rdkit/linux-64::boost-1.63.0-py36h415b752_1\n",
            "  bzip2              conda-forge/linux-64::bzip2-1.0.8-h516909a_2\n",
            "  c-ares             conda-forge/linux-64::c-ares-1.15.0-h516909a_1001\n",
            "  cairo              conda-forge/linux-64::cairo-1.14.12-he56eebe_3\n",
            "  cudatoolkit        pkgs/main/linux-64::cudatoolkit-9.0-h13b8566_0\n",
            "  cudnn              pkgs/main/linux-64::cudnn-7.6.5-cuda9.0_0\n",
            "  cupti              pkgs/main/linux-64::cupti-9.0.176-0\n",
            "  cycler             conda-forge/noarch::cycler-0.10.0-py_2\n",
            "  cython             conda-forge/linux-64::cython-0.29.15-py36h831f99a_1\n",
            "  dbus               conda-forge/linux-64::dbus-1.13.0-h4e0c4b3_1000\n",
            "  decorator          conda-forge/noarch::decorator-4.4.2-py_0\n",
            "  deepchem-gpu       deepchem/linux-64::deepchem-gpu-2.1.0-py36_0\n",
            "  defusedxml         conda-forge/noarch::defusedxml-0.6.0-py_0\n",
            "  entrypoints        conda-forge/linux-64::entrypoints-0.3-py36h9f0ad1d_1001\n",
            "  expat              conda-forge/linux-64::expat-2.2.9-he1b5a44_2\n",
            "  fftw3f             omnia/linux-64::fftw3f-3.3.4-2\n",
            "  fontconfig         conda-forge/linux-64::fontconfig-2.13.0-hd36ec8e_5\n",
            "  freetype           conda-forge/linux-64::freetype-2.8.1-hfa320df_1\n",
            "  gast               conda-forge/noarch::gast-0.3.3-py_0\n",
            "  gettext            conda-forge/linux-64::gettext-0.19.8.1-hc5be6a0_1002\n",
            "  glib               conda-forge/linux-64::glib-2.55.0-h464dc38_2\n",
            "  grpcio             conda-forge/linux-64::grpcio-1.16.0-py36h4f00d22_1000\n",
            "  gst-plugins-base   conda-forge/linux-64::gst-plugins-base-1.12.5-h3865690_1000\n",
            "  gstreamer          conda-forge/linux-64::gstreamer-1.12.5-h61a6719_0\n",
            "  hdf5               conda-forge/linux-64::hdf5-1.10.5-nompi_h3c11f04_1104\n",
            "  html5lib           conda-forge/linux-64::html5lib-0.9999999-py36_0\n",
            "  icu                conda-forge/linux-64::icu-58.2-hf484d3e_1000\n",
            "  importlib-metadata conda-forge/linux-64::importlib-metadata-1.5.0-py36h9f0ad1d_1\n",
            "  importlib_metadata conda-forge/noarch::importlib_metadata-1.5.0-1\n",
            "  intel-openmp       pkgs/main/linux-64::intel-openmp-2019.4-243\n",
            "  ipykernel          conda-forge/linux-64::ipykernel-5.1.4-py36h5ca1d4c_0\n",
            "  ipython            conda-forge/linux-64::ipython-7.13.0-py36h95af2a2_1\n",
            "  ipython_genutils   conda-forge/noarch::ipython_genutils-0.2.0-py_1\n",
            "  ipywidgets         conda-forge/noarch::ipywidgets-7.5.1-py_0\n",
            "  jedi               conda-forge/linux-64::jedi-0.16.0-py36h9f0ad1d_1\n",
            "  jinja2             conda-forge/noarch::jinja2-2.11.1-py_0\n",
            "  joblib             conda-forge/linux-64::joblib-0.11-py36_0\n",
            "  jpeg               conda-forge/linux-64::jpeg-9c-h14c3975_1001\n",
            "  jsonschema         conda-forge/linux-64::jsonschema-3.2.0-py36h9f0ad1d_1\n",
            "  jupyter            conda-forge/noarch::jupyter-1.0.0-py_2\n",
            "  jupyter_client     conda-forge/noarch::jupyter_client-6.0.0-py_0\n",
            "  jupyter_console    conda-forge/noarch::jupyter_console-6.1.0-py_1\n",
            "  jupyter_core       conda-forge/linux-64::jupyter_core-4.6.3-py36h9f0ad1d_1\n",
            "  kiwisolver         conda-forge/linux-64::kiwisolver-1.1.0-py36hdb11119_1\n",
            "  libgfortran-ng     conda-forge/linux-64::libgfortran-ng-7.3.0-hdf63c60_5\n",
            "  libiconv           conda-forge/linux-64::libiconv-1.15-h516909a_1005\n",
            "  libpng             conda-forge/linux-64::libpng-1.6.37-hed695b0_0\n",
            "  libprotobuf        conda-forge/linux-64::libprotobuf-3.11.3-h8b12597_0\n",
            "  libsodium          conda-forge/linux-64::libsodium-1.0.17-h516909a_0\n",
            "  libtiff            conda-forge/linux-64::libtiff-4.0.9-h648cc4a_1002\n",
            "  libuuid            conda-forge/linux-64::libuuid-2.32.1-h14c3975_1000\n",
            "  libxcb             conda-forge/linux-64::libxcb-1.13-h14c3975_1002\n",
            "  libxml2            conda-forge/linux-64::libxml2-2.9.9-h13577e0_2\n",
            "  lzo                conda-forge/linux-64::lzo-2.10-h14c3975_1000\n",
            "  markdown           conda-forge/noarch::markdown-3.2.1-py_0\n",
            "  markupsafe         conda-forge/linux-64::markupsafe-1.1.1-py36h8c4c3a4_1\n",
            "  matplotlib         pkgs/main/linux-64::matplotlib-2.2.2-py36h0e671d2_0\n",
            "  mdtraj             deepchem/linux-64::mdtraj-1.9.1-py36_1\n",
            "  mistune            conda-forge/linux-64::mistune-0.8.4-py36h516909a_1000\n",
            "  mkl                pkgs/main/linux-64::mkl-2018.0.3-1\n",
            "  mkl_fft            conda-forge/linux-64::mkl_fft-1.0.10-py36_0\n",
            "  mkl_random         conda-forge/linux-64::mkl_random-1.0.2-py36_0\n",
            "  mock               conda-forge/linux-64::mock-3.0.5-py36h9f0ad1d_1\n",
            "  nbconvert          conda-forge/linux-64::nbconvert-5.6.1-py36_0\n",
            "  nbformat           conda-forge/noarch::nbformat-5.0.4-py_0\n",
            "  networkx           conda-forge/noarch::networkx-2.1-py_1\n",
            "  notebook           conda-forge/linux-64::notebook-6.0.3-py36_0\n",
            "  numexpr            conda-forge/linux-64::numexpr-2.7.1-py36hb3f55d8_0\n",
            "  numpy              pkgs/main/linux-64::numpy-1.15.4-py36h1d66e8a_0\n",
            "  numpy-base         pkgs/main/linux-64::numpy-base-1.15.4-py36h81de0dd_0\n",
            "  olefile            conda-forge/noarch::olefile-0.46-py_0\n",
            "  openmm             omnia/linux-64::openmm-7.4.1-py36_cuda101_rc_1\n",
            "  pandas             conda-forge/linux-64::pandas-0.22.0-py36_1\n",
            "  pandoc             conda-forge/linux-64::pandoc-2.9.2-0\n",
            "  pandocfilters      conda-forge/noarch::pandocfilters-1.4.2-py_1\n",
            "  parso              conda-forge/noarch::parso-0.6.2-py_0\n",
            "  pcre               conda-forge/linux-64::pcre-8.44-he1b5a44_0\n",
            "  pdbfixer           omnia/linux-64::pdbfixer-1.4-py36_0\n",
            "  pexpect            conda-forge/linux-64::pexpect-4.8.0-py36h9f0ad1d_1\n",
            "  pickleshare        conda-forge/linux-64::pickleshare-0.7.5-py36h9f0ad1d_1001\n",
            "  pillow             conda-forge/linux-64::pillow-5.0.0-py36_0\n",
            "  pixman             conda-forge/linux-64::pixman-0.34.0-h14c3975_1003\n",
            "  prometheus_client  conda-forge/noarch::prometheus_client-0.7.1-py_0\n",
            "  prompt-toolkit     conda-forge/noarch::prompt-toolkit-3.0.4-py_0\n",
            "  prompt_toolkit     conda-forge/noarch::prompt_toolkit-3.0.4-0\n",
            "  protobuf           conda-forge/linux-64::protobuf-3.11.3-py36he1b5a44_0\n",
            "  pthread-stubs      conda-forge/linux-64::pthread-stubs-0.4-h14c3975_1001\n",
            "  ptyprocess         conda-forge/noarch::ptyprocess-0.6.0-py_1001\n",
            "  pygments           conda-forge/noarch::pygments-2.6.1-py_0\n",
            "  pyparsing          conda-forge/noarch::pyparsing-2.4.6-py_0\n",
            "  pyqt               conda-forge/linux-64::pyqt-5.6.0-py36h13b7fb3_1008\n",
            "  pyrsistent         conda-forge/linux-64::pyrsistent-0.15.7-py36h8c4c3a4_1\n",
            "  pytables           conda-forge/linux-64::pytables-3.6.1-py36h9f153d1_1\n",
            "  python-dateutil    conda-forge/noarch::python-dateutil-2.8.1-py_0\n",
            "  python_abi         conda-forge/linux-64::python_abi-3.6-1_cp36m\n",
            "  pytz               conda-forge/noarch::pytz-2019.3-py_0\n",
            "  pyzmq              conda-forge/linux-64::pyzmq-19.0.0-py36h9947dbf_1\n",
            "  qt                 pkgs/main/linux-64::qt-5.6.2-hd25b39d_14\n",
            "  qtconsole          conda-forge/noarch::qtconsole-4.7.1-py_0\n",
            "  qtpy               conda-forge/noarch::qtpy-1.9.0-py_0\n",
            "  rdkit              rdkit/linux-64::rdkit-2017.09.1-py36_1\n",
            "  scikit-learn       pkgs/main/linux-64::scikit-learn-0.19.1-py36hedc7406_0\n",
            "  scipy              pkgs/main/linux-64::scipy-1.1.0-py36hfa4b5c9_1\n",
            "  send2trash         conda-forge/noarch::send2trash-1.5.0-py_0\n",
            "  simdna             deepchem/noarch::simdna-0.4.2-py_0\n",
            "  sip                conda-forge/linux-64::sip-4.18.1-py36hf484d3e_1000\n",
            "  tbb                conda-forge/linux-64::tbb-2020.1-hc9558a2_0\n",
            "  tbb4py             conda-forge/linux-64::tbb4py-2020.1-py36hc9558a2_0\n",
            "  tensorboard        conda-forge/linux-64::tensorboard-1.6.0-py36_0\n",
            "  tensorflow-gpu     pkgs/main/linux-64::tensorflow-gpu-1.6.0-0\n",
            "  tensorflow-gpu-ba~ pkgs/main/linux-64::tensorflow-gpu-base-1.6.0-py36hcdda91b_1\n",
            "  termcolor          conda-forge/noarch::termcolor-1.1.0-py_2\n",
            "  terminado          conda-forge/linux-64::terminado-0.8.3-py36h9f0ad1d_1\n",
            "  testpath           conda-forge/noarch::testpath-0.4.4-py_0\n",
            "  tornado            conda-forge/linux-64::tornado-6.0.4-py36h8c4c3a4_1\n",
            "  traitlets          conda-forge/linux-64::traitlets-4.3.3-py36h9f0ad1d_1\n",
            "  wcwidth            conda-forge/noarch::wcwidth-0.1.8-py_0\n",
            "  webencodings       conda-forge/noarch::webencodings-0.5.1-py_1\n",
            "  werkzeug           conda-forge/noarch::werkzeug-1.0.0-py_0\n",
            "  widgetsnbextension conda-forge/linux-64::widgetsnbextension-3.5.1-py36_0\n",
            "  xgboost            conda-forge/linux-64::xgboost-0.6a2-py36_2\n",
            "  xorg-kbproto       conda-forge/linux-64::xorg-kbproto-1.0.7-h14c3975_1002\n",
            "  xorg-libice        conda-forge/linux-64::xorg-libice-1.0.10-h516909a_0\n",
            "  xorg-libsm         conda-forge/linux-64::xorg-libsm-1.2.3-h84519dc_1000\n",
            "  xorg-libx11        conda-forge/linux-64::xorg-libx11-1.6.9-h516909a_0\n",
            "  xorg-libxau        conda-forge/linux-64::xorg-libxau-1.0.9-h14c3975_0\n",
            "  xorg-libxdmcp      conda-forge/linux-64::xorg-libxdmcp-1.1.3-h516909a_0\n",
            "  xorg-libxext       conda-forge/linux-64::xorg-libxext-1.3.4-h516909a_0\n",
            "  xorg-libxrender    conda-forge/linux-64::xorg-libxrender-0.9.10-h516909a_1002\n",
            "  xorg-renderproto   conda-forge/linux-64::xorg-renderproto-0.11.1-h14c3975_1002\n",
            "  xorg-xextproto     conda-forge/linux-64::xorg-xextproto-7.3.0-h14c3975_1002\n",
            "  xorg-xproto        conda-forge/linux-64::xorg-xproto-7.0.31-h14c3975_1007\n",
            "  zeromq             conda-forge/linux-64::zeromq-4.3.2-he1b5a44_2\n",
            "  zipp               conda-forge/noarch::zipp-3.1.0-py_0\n",
            "\n",
            "The following packages will be UPDATED:\n",
            "\n",
            "  certifi              pkgs/main::certifi-2019.11.28-py37_0 --> conda-forge::certifi-2019.11.28-py36h9f0ad1d_1\n",
            "  chardet                pkgs/main::chardet-3.0.4-py37_1003 --> conda-forge::chardet-3.0.4-py36h9f0ad1d_1006\n",
            "  conda                       pkgs/main::conda-4.8.2-py37_0 --> conda-forge::conda-4.8.3-py36h9f0ad1d_1\n",
            "  conda-package-han~ pkgs/main::conda-package-handling-1.6~ --> conda-forge::conda-package-handling-1.6.0-py36h8c4c3a4_2\n",
            "  pip                 pkgs/main/linux-64::pip-20.0.2-py37_1 --> conda-forge/noarch::pip-20.0.2-py_2\n",
            "  pycosat            pkgs/main::pycosat-0.6.3-py37h7b6447c~ --> conda-forge::pycosat-0.6.3-py36h8c4c3a4_1004\n",
            "  pycparser          pkgs/main/linux-64::pycparser-2.19-py~ --> conda-forge/noarch::pycparser-2.20-py_0\n",
            "  pysocks                   pkgs/main::pysocks-1.7.1-py37_0 --> conda-forge::pysocks-1.7.1-py36h9f0ad1d_1\n",
            "  setuptools            pkgs/main::setuptools-45.2.0-py37_0 --> conda-forge::setuptools-46.0.0-py36h9f0ad1d_2\n",
            "  six                 pkgs/main/linux-64::six-1.14.0-py37_0 --> conda-forge/noarch::six-1.14.0-py_1\n",
            "  wheel              pkgs/main/linux-64::wheel-0.34.2-py37~ --> conda-forge/noarch::wheel-0.34.2-py_1\n",
            "\n",
            "The following packages will be SUPERSEDED by a higher-priority channel:\n",
            "\n",
            "  asn1crypto             pkgs/main::asn1crypto-1.3.0-py37_0 --> conda-forge::asn1crypto-1.3.0-py36_0\n",
            "  ca-certificates     pkgs/main::ca-certificates-2020.1.1-0 --> conda-forge::ca-certificates-2019.11.28-hecc5488_0\n",
            "  cffi                pkgs/main::cffi-1.14.0-py37h2e261b9_0 --> conda-forge::cffi-1.14.0-py36hd463f26_0\n",
            "  cryptography       pkgs/main::cryptography-2.8-py37h1ba5~ --> conda-forge::cryptography-2.5-py36hb7f436b_1\n",
            "  idna                           pkgs/main::idna-2.8-py37_0 --> conda-forge::idna-2.6-py36_1\n",
            "  openssl              pkgs/main::openssl-1.1.1d-h7b6447c_4 --> conda-forge::openssl-1.0.2u-h516909a_0\n",
            "  pyopenssl              pkgs/main::pyopenssl-19.1.0-py37_0 --> conda-forge::pyopenssl-19.0.0-py36_0\n",
            "  python                 pkgs/main::python-3.7.6-h0371630_2 --> conda-forge::python-3.6.6-hd21baee_1003\n",
            "  requests                pkgs/main::requests-2.22.0-py37_1 --> conda-forge::requests-2.18.4-py36_1\n",
            "  ruamel_yaml        pkgs/main::ruamel_yaml-0.15.87-py37h7~ --> conda-forge::ruamel_yaml-0.15.71-py36h14c3975_1000\n",
            "  urllib3                  pkgs/main::urllib3-1.25.8-py37_0 --> conda-forge::urllib3-1.22-py36_0\n",
            "\n",
            "\n",
            "\n",
            "Downloading and Extracting Packages\n",
            "chardet-3.0.4        | 188 KB    | : 100% 1.0/1 [00:00<00:00,  5.80it/s]                \n",
            "scipy-1.1.0          | 13.2 MB   | : 100% 1.0/1 [00:00<00:00,  3.47s/it]               \n",
            "expat-2.2.9          | 191 KB    | : 100% 1.0/1 [00:00<00:00, 12.37it/s]\n",
            "gstreamer-1.12.5     | 2.1 MB    | : 100% 1.0/1 [00:00<00:00,  2.46it/s]\n",
            "prompt-toolkit-3.0.4 | 233 KB    | : 100% 1.0/1 [00:00<00:00,  9.31it/s]\n",
            "libtiff-4.0.9        | 566 KB    | : 100% 1.0/1 [00:00<00:00,  7.02it/s]\n",
            "mistune-0.8.4        | 53 KB     | : 100% 1.0/1 [00:00<00:00, 11.60it/s]\n",
            "sip-4.18.1           | 277 KB    | : 100% 1.0/1 [00:00<00:00, 12.11it/s]\n",
            "cffi-1.14.0          | 221 KB    | : 100% 1.0/1 [00:00<00:00, 11.54it/s]\n",
            "xorg-xextproto-7.3.0 | 27 KB     | : 100% 1.0/1 [00:00<00:00, 13.61it/s]\n",
            "jupyter_client-6.0.0 | 71 KB     | : 100% 1.0/1 [00:00<00:00,  9.22it/s]\n",
            "terminado-0.8.3      | 23 KB     | : 100% 1.0/1 [00:00<00:00, 21.40it/s]\n",
            "libsodium-1.0.17     | 330 KB    | : 100% 1.0/1 [00:00<00:00, 10.73it/s]\n",
            "tensorflow-gpu-1.6.0 | 4 KB      | : 100% 1.0/1 [00:00<00:00,  9.95it/s]\n",
            "importlib-metadata-1 | 42 KB     | : 100% 1.0/1 [00:00<00:00, 21.72it/s]\n",
            "pexpect-4.8.0        | 79 KB     | : 100% 1.0/1 [00:00<00:00, 18.13it/s]\n",
            "ca-certificates-2019 | 145 KB    | : 100% 1.0/1 [00:00<00:00, 14.35it/s]\n",
            "tornado-6.0.4        | 639 KB    | : 100% 1.0/1 [00:00<00:00,  5.79it/s]\n",
            "joblib-0.11          | 193 KB    | : 100% 1.0/1 [00:00<00:00, 11.56it/s]\n",
            "xorg-libsm-1.2.3     | 25 KB     | : 100% 1.0/1 [00:00<00:00, 26.50it/s]\n",
            "pillow-5.0.0         | 975 KB    | : 100% 1.0/1 [00:00<00:00,  4.69it/s]\n",
            "importlib_metadata-1 | 3 KB      | : 100% 1.0/1 [00:00<00:00, 31.13it/s]\n",
            "zipp-3.1.0           | 10 KB     | : 100% 1.0/1 [00:00<00:00, 22.49it/s]\n",
            "mdtraj-1.9.1         | 5.9 MB    | : 100% 1.0/1 [00:02<00:00, 52.97s/it]               \n",
            "grpcio-1.16.0        | 1.0 MB    | : 100% 1.0/1 [00:00<00:00,  4.04it/s]\n",
            "attrs-19.3.0         | 35 KB     | : 100% 1.0/1 [00:00<00:00, 19.50it/s]\n",
            "widgetsnbextension-3 | 1.8 MB    | : 100% 1.0/1 [00:00<00:00,  2.29it/s]\n",
            "qt-5.6.2             | 34.8 MB   | : 100% 1.0/1 [00:01<00:00,  1.72s/it]              \n",
            "jpeg-9c              | 251 KB    | : 100% 1.0/1 [00:00<00:00, 12.40it/s]\n",
            "mkl_fft-1.0.10       | 650 KB    | : 100% 1.0/1 [00:00<00:00,  6.92it/s]\n",
            "gast-0.3.3           | 12 KB     | : 100% 1.0/1 [00:00<00:00, 28.09it/s]\n",
            "numpy-base-1.15.4    | 3.4 MB    | : 100% 1.0/1 [00:00<00:00,  4.17it/s]\n",
            "cython-0.29.15       | 2.2 MB    | : 100% 1.0/1 [00:00<00:00,  2.08it/s]\n",
            "webencodings-0.5.1   | 12 KB     | : 100% 1.0/1 [00:00<00:00, 25.11it/s]\n",
            "jupyter-1.0.0        | 4 KB      | : 100% 1.0/1 [00:00<00:00, 19.74it/s]\n",
            "qtconsole-4.7.1      | 87 KB     | : 100% 1.0/1 [00:00<00:00, 19.98it/s]\n",
            "libprotobuf-3.11.3   | 4.8 MB    | : 100% 1.0/1 [00:01<00:00,  1.01s/it]\n",
            "pandocfilters-1.4.2  | 9 KB      | : 100% 1.0/1 [00:00<00:00, 23.20it/s]\n",
            "html5lib-0.9999999   | 181 KB    | : 100% 1.0/1 [00:00<00:00, 10.00it/s]\n",
            "prometheus_client-0. | 38 KB     | : 100% 1.0/1 [00:00<00:00, 25.98it/s]\n",
            "idna-2.6             | 122 KB    | : 100% 1.0/1 [00:00<00:00, 18.78it/s]\n",
            "jedi-0.16.0          | 774 KB    | : 100% 1.0/1 [00:00<00:00,  3.19it/s]\n",
            "libxcb-1.13          | 396 KB    | : 100% 1.0/1 [00:00<00:00,  7.30it/s]\n",
            "six-1.14.0           | 13 KB     | : 100% 1.0/1 [00:00<00:00, 25.43it/s]\n",
            "astor-0.7.1          | 22 KB     | : 100% 1.0/1 [00:00<00:00, 27.26it/s]\n",
            "intel-openmp-2019.4  | 729 KB    | : 100% 1.0/1 [00:00<00:00,  9.53it/s]\n",
            "protobuf-3.11.3      | 696 KB    | : 100% 1.0/1 [00:00<00:00,  4.51it/s]\n",
            "pyrsistent-0.15.7    | 89 KB     | : 100% 1.0/1 [00:00<00:00, 17.78it/s]\n",
            "certifi-2019.11.28   | 149 KB    | : 100% 1.0/1 [00:00<00:00, 17.60it/s]\n",
            "blas-1.0             | 6 KB      | : 100% 1.0/1 [00:00<00:00, 13.04it/s]\n",
            "hdf5-1.10.5          | 3.1 MB    | : 100% 1.0/1 [00:00<00:00,  1.95it/s]\n",
            "termcolor-1.1.0      | 6 KB      | : 100% 1.0/1 [00:00<00:00, 25.83it/s]\n",
            "qtpy-1.9.0           | 34 KB     | : 100% 1.0/1 [00:00<00:00, 21.03it/s]\n",
            "jupyter_console-6.1. | 21 KB     | : 100% 1.0/1 [00:00<00:00, 22.91it/s]\n",
            "xorg-libice-1.0.10   | 57 KB     | : 100% 1.0/1 [00:00<00:00, 17.90it/s]\n",
            "xorg-libxdmcp-1.1.3  | 18 KB     | : 100% 1.0/1 [00:00<00:00, 31.15it/s]\n",
            "rdkit-2017.09.1      | 19.7 MB   | : 100% 1.0/1 [00:04<00:00, 47.26s/it]               \n",
            "icu-58.2             | 22.6 MB   | : 100% 1.0/1 [00:03<00:00,  4.91s/it]               \n",
            "markupsafe-1.1.1     | 26 KB     | : 100% 1.0/1 [00:00<00:00, 27.93it/s]\n",
            "xorg-renderproto-0.1 | 8 KB      | : 100% 1.0/1 [00:00<00:00, 34.50it/s]\n",
            "cupti-9.0.176        | 1.4 MB    | : 100% 1.0/1 [00:00<00:00,  7.67it/s]\n",
            "absl-py-0.9.0        | 162 KB    | : 100% 1.0/1 [00:00<00:00,  8.58it/s]\n",
            "matplotlib-2.2.2     | 4.8 MB    | : 100% 1.0/1 [00:00<00:00,  3.80it/s]\n",
            "pyqt-5.6.0           | 5.4 MB    | : 100% 1.0/1 [00:01<00:00,  1.23s/it]               \n",
            "networkx-2.1         | 1.1 MB    | : 100% 1.0/1 [00:00<00:00,  3.76it/s]\n",
            "mkl_random-1.0.2     | 1.3 MB    | : 100% 1.0/1 [00:00<00:00,  3.98it/s]\n",
            "pthread-stubs-0.4    | 5 KB      | : 100% 1.0/1 [00:00<00:00, 33.30it/s]\n",
            "bzip2-1.0.8          | 396 KB    | : 100% 1.0/1 [00:00<00:00,  9.06it/s]\n",
            "pycosat-0.6.3        | 107 KB    | : 100% 1.0/1 [00:00<00:00, 20.87it/s]\n",
            "parso-0.6.2          | 66 KB     | : 100% 1.0/1 [00:00<00:00, 19.05it/s]\n",
            "libgfortran-ng-7.3.0 | 1.7 MB    | : 100% 1.0/1 [00:00<00:00,  3.01it/s]\n",
            "ipython-7.13.0       | 1.1 MB    | : 100% 1.0/1 [00:00<00:00,  3.49it/s]\n",
            "requests-2.18.4      | 91 KB     | : 100% 1.0/1 [00:00<00:00, 15.84it/s]\n",
            "blosc-1.17.1         | 886 KB    | : 100% 1.0/1 [00:00<00:00,  5.28it/s]\n",
            "traitlets-4.3.3      | 133 KB    | : 100% 1.0/1 [00:00<00:00, 16.17it/s]\n",
            "send2trash-1.5.0     | 12 KB     | : 100% 1.0/1 [00:00<00:00, 33.03it/s]\n",
            "jupyter_core-4.6.3   | 71 KB     | : 100% 1.0/1 [00:00<00:00, 19.77it/s]\n",
            "ipython_genutils-0.2 | 21 KB     | : 100% 1.0/1 [00:00<00:00, 29.51it/s]\n",
            "xorg-libxau-1.0.9    | 13 KB     | : 100% 1.0/1 [00:00<00:00, 26.74it/s]\n",
            "pytz-2019.3          | 237 KB    | : 100% 1.0/1 [00:00<00:00,  7.42it/s]\n",
            "c-ares-1.15.0        | 100 KB    | : 100% 1.0/1 [00:00<00:00, 12.91it/s]\n",
            "zeromq-4.3.2         | 668 KB    | : 100% 1.0/1 [00:00<00:00,  5.14it/s]\n",
            "deepchem-gpu-2.1.0   | 1.9 MB    | : 100% 1.0/1 [00:01<00:00, 23.42s/it]               \n",
            "mkl-2018.0.3         | 126.9 MB  | : 100% 1.0/1 [00:03<00:00,  3.95s/it]               \n",
            "prompt_toolkit-3.0.4 | 4 KB      | : 100% 1.0/1 [00:00<00:00, 24.99it/s]\n",
            "cycler-0.10.0        | 9 KB      | : 100% 1.0/1 [00:00<00:00, 29.06it/s]\n",
            "openmm-7.4.1         | 11.9 MB   | : 100% 1.0/1 [00:03<00:00, 78.72s/it]                \n",
            "libiconv-1.15        | 2.0 MB    | : 100% 1.0/1 [00:00<00:00,  3.32it/s]\n",
            "notebook-6.0.3       | 6.2 MB    | : 100% 1.0/1 [00:01<00:00,  1.52s/it]               \n",
            "xgboost-0.6a2        | 1.1 MB    | : 100% 1.0/1 [00:00<00:00,  3.70it/s]\n",
            "pcre-8.44            | 261 KB    | : 100% 1.0/1 [00:00<00:00,  9.36it/s]\n",
            "nbconvert-5.6.1      | 467 KB    | : 100% 1.0/1 [00:00<00:00,  6.75it/s]\n",
            "pandas-0.22.0        | 26.1 MB   | : 100% 1.0/1 [00:04<00:00,  3.70s/it]               \n",
            "fontconfig-2.13.0    | 284 KB    | : 100% 1.0/1 [00:00<00:00, 10.82it/s]\n",
            "gettext-0.19.8.1     | 3.6 MB    | : 100% 1.0/1 [00:01<00:00,  1.56s/it]\n",
            "werkzeug-1.0.0       | 238 KB    | : 100% 1.0/1 [00:00<00:00, 11.07it/s]\n",
            "python-dateutil-2.8. | 220 KB    | : 100% 1.0/1 [00:00<00:00, 15.63it/s]\n",
            "fftw3f-3.3.4         | 1.2 MB    | : 100% 1.0/1 [00:01<00:00, 10.41s/it]               \n",
            "xorg-libx11-1.6.9    | 918 KB    | : 100% 1.0/1 [00:00<00:00,  4.62it/s]\n",
            "boost-1.63.0         | 11.8 MB   | : 100% 1.0/1 [00:05<00:00,  5.37s/it]               \n",
            "pyparsing-2.4.6      | 59 KB     | : 100% 1.0/1 [00:00<00:00, 20.03it/s]\n",
            "jinja2-2.11.1        | 94 KB     | : 100% 1.0/1 [00:00<00:00, 16.44it/s]\n",
            "wheel-0.34.2         | 24 KB     | : 100% 1.0/1 [00:00<00:00, 23.79it/s]\n",
            "python-3.6.6         | 29.0 MB   | : 100% 1.0/1 [00:04<00:00,  4.31s/it]               \n",
            "pandoc-2.9.2         | 16.8 MB   | : 100% 1.0/1 [00:03<00:00,  3.89s/it]               \n",
            "bleach-1.5.0         | 23 KB     | : 100% 1.0/1 [00:00<00:00, 10.47it/s]\n",
            "xorg-xproto-7.0.31   | 72 KB     | : 100% 1.0/1 [00:00<00:00, 20.35it/s]\n",
            "decorator-4.4.2      | 11 KB     | : 100% 1.0/1 [00:00<00:00, 25.94it/s]\n",
            "cairo-1.14.12        | 1.3 MB    | : 100% 1.0/1 [00:00<00:00,  3.13it/s]\n",
            "setuptools-46.0.0    | 638 KB    | : 100% 1.0/1 [00:00<00:00,  4.95it/s]\n",
            "markdown-3.2.1       | 61 KB     | : 100% 1.0/1 [00:00<00:00, 19.45it/s]\n",
            "xorg-libxext-1.3.4   | 51 KB     | : 100% 1.0/1 [00:00<00:00, 21.56it/s]\n",
            "cudnn-7.6.5          | 143.3 MB  | : 100% 1.0/1 [00:04<00:00,  4.22s/it]               \n",
            "numpy-1.15.4         | 34 KB     | : 100% 1.0/1 [00:00<00:00, 10.84it/s]\n",
            "jsonschema-3.2.0     | 89 KB     | : 100% 1.0/1 [00:00<00:00, 17.30it/s]\n",
            "urllib3-1.22         | 154 KB    | : 100% 1.0/1 [00:00<00:00, 13.94it/s]\n",
            "asn1crypto-1.3.0     | 159 KB    | : 100% 1.0/1 [00:00<00:00, 11.04it/s]\n",
            "pygments-2.6.1       | 683 KB    | : 100% 1.0/1 [00:00<00:00,  5.47it/s]\n",
            "tbb4py-2020.1        | 245 KB    | : 100% 1.0/1 [00:00<00:00, 13.16it/s]\n",
            "conda-package-handli | 947 KB    | : 100% 1.0/1 [00:00<00:00,  5.72it/s]\n",
            "nbformat-5.0.4       | 98 KB     | : 100% 1.0/1 [00:00<00:00, 17.75it/s]\n",
            "freetype-2.8.1       | 789 KB    | : 100% 1.0/1 [00:00<00:00,  5.45it/s]\n",
            "pytables-3.6.1       | 1.5 MB    | : 100% 1.0/1 [00:00<00:00,  2.99it/s]\n",
            "xorg-kbproto-1.0.7   | 26 KB     | : 100% 1.0/1 [00:00<00:00, 21.03it/s]\n",
            "pixman-0.34.0        | 595 KB    | : 100% 1.0/1 [00:00<00:00,  6.40it/s]\n",
            "xorg-libxrender-0.9. | 31 KB     | : 100% 1.0/1 [00:00<00:00, 27.14it/s]\n",
            "tensorboard-1.6.0    | 2.9 MB    | : 100% 1.0/1 [00:00<00:00,  2.38it/s]\n",
            "ruamel_yaml-0.15.71  | 257 KB    | : 100% 1.0/1 [00:00<00:00, 11.58it/s]\n",
            "dbus-1.13.0          | 558 KB    | : 100% 1.0/1 [00:00<00:00,  7.35it/s]\n",
            "lzo-2.10             | 319 KB    | : 100% 1.0/1 [00:00<00:00, 10.38it/s]\n",
            "libpng-1.6.37        | 343 KB    | : 100% 1.0/1 [00:00<00:00, 10.82it/s]\n",
            "tbb-2020.1           | 1.4 MB    | : 100% 1.0/1 [00:00<00:00,  4.12it/s]\n",
            "testpath-0.4.4       | 85 KB     | : 100% 1.0/1 [00:00<00:00, 20.46it/s]\n",
            "pyopenssl-19.0.0     | 81 KB     | : 100% 1.0/1 [00:00<00:00, 14.91it/s]\n",
            "ipykernel-5.1.4      | 160 KB    | : 100% 1.0/1 [00:00<00:00, 11.44it/s]\n",
            "libxml2-2.9.9        | 1.3 MB    | : 100% 1.0/1 [00:00<00:00,  2.68it/s]\n",
            "kiwisolver-1.1.0     | 86 KB     | : 100% 1.0/1 [00:00<00:00, 20.33it/s]\n",
            "tensorflow-gpu-base- | 68.1 MB   | : 100% 1.0/1 [00:09<00:00,  9.11s/it]               \n",
            "cryptography-2.5     | 645 KB    | : 100% 1.0/1 [00:13<00:00, 13.27s/it]\n",
            "pycparser-2.20       | 89 KB     | : 100% 1.0/1 [00:00<00:00,  3.47it/s]\n",
            "openssl-1.0.2u       | 3.2 MB    | : 100% 1.0/1 [00:00<00:00,  1.64it/s]\n",
            "cudatoolkit-9.0      | 237.0 MB  | : 100% 1.0/1 [00:19<00:00, 19.35s/it]               \n",
            "python_abi-3.6       | 4 KB      | : 100% 1.0/1 [00:00<00:00,  1.39it/s]\n",
            "wcwidth-0.1.8        | 19 KB     | : 100% 1.0/1 [00:00<00:00, 10.82it/s]\n",
            "numexpr-2.7.1        | 196 KB    | : 100% 1.0/1 [00:00<00:00, 10.16it/s]\n",
            "scikit-learn-0.19.1  | 3.9 MB    | : 100% 1.0/1 [00:00<00:00,  3.30it/s]\n",
            "olefile-0.46         | 31 KB     | : 100% 1.0/1 [00:00<00:00, 24.37it/s]\n",
            "libuuid-2.32.1       | 26 KB     | : 100% 1.0/1 [00:00<00:00, 21.79it/s]\n",
            "ptyprocess-0.6.0     | 15 KB     | : 100% 1.0/1 [00:00<00:00, 30.98it/s]\n",
            "defusedxml-0.6.0     | 22 KB     | : 100% 1.0/1 [00:00<00:00, 26.76it/s]\n",
            "pip-20.0.2           | 1.0 MB    | : 100% 1.0/1 [00:00<00:00,  3.66it/s]\n",
            "conda-4.8.3          | 3.0 MB    | : 100% 1.0/1 [00:00<00:00,  1.64it/s]\n",
            "pdbfixer-1.4         | 187 KB    | : 100% 1.0/1 [00:01<00:00,  1.08s/it]                \n",
            "ipywidgets-7.5.1     | 101 KB    | : 100% 1.0/1 [00:00<00:00, 16.72it/s]\n",
            "pickleshare-0.7.5    | 13 KB     | : 100% 1.0/1 [00:00<00:00, 21.06it/s]\n",
            "gst-plugins-base-1.1 | 4.9 MB    | : 100% 1.0/1 [00:00<00:00,  1.24it/s]\n",
            "pyzmq-19.0.0         | 503 KB    | : 100% 1.0/1 [00:00<00:00,  5.84it/s]\n",
            "simdna-0.4.2         | 627 KB    | : 100% 1.0/1 [00:00<00:00,  1.32it/s]               \n",
            "glib-2.55.0          | 6.1 MB    | : 100% 1.0/1 [00:01<00:00,  1.39s/it]               \n",
            "entrypoints-0.3      | 12 KB     | : 100% 1.0/1 [00:00<00:00, 27.22it/s]\n",
            "backcall-0.1.0       | 13 KB     | : 100% 1.0/1 [00:00<00:00, 28.52it/s]\n",
            "mock-3.0.5           | 44 KB     | : 100% 1.0/1 [00:00<00:00, 18.55it/s]\n",
            "pysocks-1.7.1        | 27 KB     | : 100% 1.0/1 [00:00<00:00, 22.52it/s]\n",
            "Preparing transaction: | \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\bdone\n",
            "Verifying transaction: \\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\bdone\n",
            "Executing transaction: / \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ b'Enabling notebook extension jupyter-js-widgets/extension...\\nPaths used for configuration of notebook: \\n    \\t/usr/local/etc/jupyter/nbconfig/notebook.d/plotlywidget.json\\n    \\t/usr/local/etc/jupyter/nbconfig/notebook.d/widgetsnbextension.json\\n    \\t/usr/local/etc/jupyter/nbconfig/notebook.json\\nPaths used for configuration of notebook: \\n    \\t/usr/local/etc/jupyter/nbconfig/notebook.d/plotlywidget.json\\n    \\t/usr/local/etc/jupyter/nbconfig/notebook.d/widgetsnbextension.json\\n      - Validating: \\x1b[32mOK\\x1b[0m\\nPaths used for configuration of notebook: \\n    \\t/usr/local/etc/jupyter/nbconfig/notebook.d/plotlywidget.json\\n    \\t/usr/local/etc/jupyter/nbconfig/notebook.d/widgetsnbextension.json\\n    \\t/usr/local/etc/jupyter/nbconfig/notebook.json\\n'\n",
            "\b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\bdone\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "31KFiVqHXgwM",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 217
        },
        "outputId": "667728a8-4042-42bb-b5f1-3fed59b6b181"
      },
      "source": [
        "#must run this after you run that^\n",
        "import sys\n",
        "if sys.version_info[0] >= 3:\n",
        "    sys.path.append('/usr/local/lib/python3.6/site-packages/')\n",
        "sys.path"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "['/tensorflow-1.15.0/python3.6',\n",
              " '',\n",
              " '/env/python',\n",
              " '/usr/lib/python36.zip',\n",
              " '/usr/lib/python3.6',\n",
              " '/usr/lib/python3.6/lib-dynload',\n",
              " '/usr/local/lib/python3.6/dist-packages',\n",
              " '/usr/lib/python3/dist-packages',\n",
              " '/usr/local/lib/python3.6/dist-packages/IPython/extensions',\n",
              " '/root/.ipython',\n",
              " '/usr/local/lib/python3.6/site-packages/']"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 2
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ZVZSbSdMkNzs",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 85
        },
        "outputId": "c2115e7b-0237-4506-8f33-af15ad7daa3c"
      },
      "source": [
        "!conda info --envs\n",
        "!conda env export -n base > environment_droplet.yml"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "# conda environments:\n",
            "#\n",
            "base                  *  /usr/local\n",
            "\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "9Sme2DmMX8Gd",
        "colab_type": "text"
      },
      "source": [
        "### **Utils**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "zZkl1jDWYQYf",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 389
        },
        "outputId": "3c1dcc98-3ad1-4740-a202-3b296c71e6a1"
      },
      "source": [
        "import csv\n",
        "import time\n",
        "import math\n",
        "import numpy as np\n",
        "import warnings\n",
        "\n",
        "from rdkit import Chem\n",
        "from rdkit import DataStructs\n",
        "from sklearn.model_selection import KFold, StratifiedKFold"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "error",
          "ename": "ModuleNotFoundError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mModuleNotFoundError\u001b[0m                       Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-114-e32bd5033633>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mwarnings\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      6\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 7\u001b[0;31m \u001b[0;32mfrom\u001b[0m \u001b[0mrdkit\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mChem\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      8\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0mrdkit\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mDataStructs\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      9\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0msklearn\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmodel_selection\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mKFold\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mStratifiedKFold\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mModuleNotFoundError\u001b[0m: No module named 'rdkit'",
            "",
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0;32m\nNOTE: If your import is failing due to a missing package, you can\nmanually install dependencies using either !pip or !apt.\n\nTo view examples of installing some common dependencies, click the\n\"Open Examples\" button below.\n\u001b[0;31m---------------------------------------------------------------------------\u001b[0m\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "otird5-PYR47",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def get_fp(smiles):\n",
        "    fp = []\n",
        "    processed_indices = []\n",
        "    invalid_indices = []\n",
        "    for i in range(len(smiles)):\n",
        "        mol = smiles[i]\n",
        "        tmp = np.array(mol2image(mol, n=2048))\n",
        "        if np.isnan(tmp[0]):\n",
        "            invalid_indices.append(i)\n",
        "        else:\n",
        "            fp.append(tmp)\n",
        "            processed_indices.append(i)\n",
        "    return np.array(fp), processed_indices, invalid_indices"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "T6X5omaFYSCz",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def get_desc(smiles, calc):\n",
        "    desc = []\n",
        "    processed_indices = []\n",
        "    invalid_indices = []\n",
        "    for i in range(len(smiles)):\n",
        "        sm = smiles[i]\n",
        "        try:\n",
        "            mol = Chem.MolFromSmiles(sm)\n",
        "            tmp = np.array(calc(mol))\n",
        "            desc.append(tmp)\n",
        "            processed_indices.append(i)\n",
        "        except:\n",
        "            invalid_indices.append(i)\n",
        "\n",
        "    desc_array = np.array(desc)\n",
        "    return desc_array, processed_indices, invalid_indices"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Beu4w0skYSNk",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def normalize_desc(desc_array, desc_mean=None):\n",
        "    desc_array = np.array(desc_array).reshape(len(desc_array), -1)\n",
        "    ind = np.zeros(desc_array.shape)\n",
        "    for i in range(desc_array.shape[0]):\n",
        "        for j in range(desc_array.shape[1]):\n",
        "            try:\n",
        "                if np.isfinite(desc_array[i, j]):\n",
        "                    ind[i, j] = 1\n",
        "            except:\n",
        "                pass\n",
        "    for i in range(desc_array.shape[0]):\n",
        "        for j in range(desc_array.shape[1]):\n",
        "            if ind[i, j] == 0:\n",
        "                desc_array[i, j] = 0\n",
        "    if desc_mean is None:\n",
        "        desc_mean = np.mean(desc_array, axis=0)\n",
        "    for i in range(desc_array.shape[0]):\n",
        "        for j in range(desc_array.shape[1]):\n",
        "            if ind[i, j] == 0:\n",
        "                desc_array[i, j] = desc_mean[j]\n",
        "    return desc_array, desc_mean"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "DJIGl9gpYcpt",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def mol2image(x, n=2048):\n",
        "    try:\n",
        "        m = Chem.MolFromSmiles(x)\n",
        "        fp = Chem.RDKFingerprint(m, maxPath=4, fpSize=n)\n",
        "        res = np.zeros(len(fp))\n",
        "        DataStructs.ConvertToNumpyArray(fp, res)\n",
        "        return res\n",
        "    except:\n",
        "        return [np.nan]"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "aPXdevqTYh01",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def sanitize_smiles(smiles, canonical=True, throw_warning=False):\n",
        "    \"\"\"\n",
        "    Takes list of SMILES strings and returns list of their sanitized versions.\n",
        "    For definition of sanitized SMILES check\n",
        "    http://www.rdkit.org/docs/api/rdkit.Chem.rdmolops-module.html#SanitizeMol\n",
        "    Parameters\n",
        "    ----------\n",
        "    smiles: list\n",
        "        list of SMILES strings\n",
        "    canonical: bool (default True)\n",
        "        parameter specifying whether SMILES will be converted to canonical\n",
        "        format\n",
        "    throw_warning: bool (default False)\n",
        "        parameter specifying whether warnings will be thrown if a SMILES is\n",
        "        invalid\n",
        "    Returns\n",
        "    -------\n",
        "    new_smiles: list\n",
        "        list of SMILES and NaNs if SMILES string is invalid or unsanitized.\n",
        "        If canonical is True, returns list of canonical SMILES.\n",
        "    When canonical is True this function is analogous to:\n",
        "        canonical_smiles(smiles, sanitize=True).\n",
        "    \"\"\"\n",
        "    new_smiles = []\n",
        "    for sm in smiles:\n",
        "        try:\n",
        "            if canonical:\n",
        "                new_smiles.append(Chem.MolToSmiles(Chem.MolFromSmiles(sm, sanitize=True)))\n",
        "            else:\n",
        "                new_smiles.append(sm)\n",
        "        except:\n",
        "            if throw_warning:\n",
        "                warnings.warn('Unsanitized SMILES string: ' + sm, UserWarning)\n",
        "            new_smiles.append('')\n",
        "    return new_smiles"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "yF3Ke4aTYkrs",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def canonical_smiles(smiles, sanitize=True, throw_warning=False):\n",
        "    \"\"\"\n",
        "    Takes list of SMILES strings and returns list of their canonical SMILES.\n",
        "    Parameters\n",
        "    ----------\n",
        "    smiles: list\n",
        "        list of SMILES strings to convert into canonical format\n",
        "    sanitize: bool (default True)\n",
        "        parameter specifying whether to sanitize SMILES or not.\n",
        "            For definition of sanitized SMILES check\n",
        "            http://www.rdkit.org/docs/api/rdkit.Chem.rdmolops-module.html#SanitizeMol\n",
        "    throw_warning: bool (default False)\n",
        "        parameter specifying whether warnings will be thrown if a SMILES is\n",
        "        invalid\n",
        "    Returns\n",
        "    -------\n",
        "    new_smiles: list\n",
        "        list of canonical SMILES and NaNs if SMILES string is invalid or\n",
        "        unsanitized (when sanitize is True)\n",
        "    When sanitize is True the function is analogous to:\n",
        "        sanitize_smiles(smiles, canonical=True).\n",
        "    \"\"\"\n",
        "    new_smiles = []\n",
        "    for sm in smiles:\n",
        "        try:\n",
        "            mol = Chem.MolFromSmiles(sm, sanitize=sanitize)\n",
        "            new_smiles.append(Chem.MolToSmiles(mol))\n",
        "        except:\n",
        "            if throw_warning:\n",
        "                warnings.warn(sm + ' can not be canonized: invalid '\n",
        "                                   'SMILES string!', UserWarning)\n",
        "            new_smiles.append('')\n",
        "    return new_smiles\n",
        "\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "BKEhwZvkYnqo",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def save_smi_to_file(filename, smiles, unique=True):\n",
        "    \"\"\"\n",
        "    Takes path to file and list of SMILES strings and writes SMILES to the specified file.\n",
        "        Args:\n",
        "            filename (str): path to the file\n",
        "            smiles (list): list of SMILES strings\n",
        "            unique (bool): parameter specifying whether to write only unique copies or not.\n",
        "        Output:\n",
        "            success (bool): defines whether operation was successfully completed or not.\n",
        "       \"\"\"\n",
        "    if unique:\n",
        "        smiles = list(set(smiles))\n",
        "    else:\n",
        "        smiles = list(smiles)\n",
        "    f = open(filename, 'w')\n",
        "    for mol in smiles:\n",
        "        f.writelines([mol, '\\n'])\n",
        "    f.close()\n",
        "    return f.closed"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "uNiHiVbrYtX1",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def read_smi_file(filename, unique=True, add_start_end_tokens=False):\n",
        "    \"\"\"\n",
        "    Reads SMILES from file. File must contain one SMILES string per line\n",
        "    with \\n token in the end of the line.\n",
        "    Args:\n",
        "        filename (str): path to the file\n",
        "        unique (bool): return only unique SMILES\n",
        "    Returns:\n",
        "        smiles (list): list of SMILES strings from specified file.\n",
        "        success (bool): defines whether operation was successfully completed or not.\n",
        "    If 'unique=True' this list contains only unique copies.\n",
        "    \"\"\"\n",
        "    f = open(filename, 'r')\n",
        "    molecules = []\n",
        "    for line in f:\n",
        "        if add_start_end_tokens:\n",
        "            molecules.append('<' + line[:-1] + '>')\n",
        "        else:\n",
        "            molecules.append(line[:-1])\n",
        "    if unique:\n",
        "        molecules = list(set(molecules))\n",
        "    else:\n",
        "        molecules = list(molecules)\n",
        "    f.close()\n",
        "    return molecules, f.closed"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "bYySqz7lYvKu",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def tokenize(smiles, tokens=None):\n",
        "    \"\"\"\n",
        "    Returns list of unique tokens, token-2-index dictionary and number of\n",
        "    unique tokens from the list of SMILES\n",
        "    Parameters\n",
        "    ----------\n",
        "        smiles: list\n",
        "            list of SMILES strings to tokenize.\n",
        "        tokens: list, str (default None)\n",
        "            list of unique tokens\n",
        "    Returns\n",
        "    -------\n",
        "        tokens: list\n",
        "            list of unique tokens/SMILES alphabet.\n",
        "        token2idx: dict\n",
        "            dictionary mapping token to its index.\n",
        "        num_tokens: int\n",
        "            number of unique tokens.\n",
        "    \"\"\"\n",
        "    if tokens is None:\n",
        "        tokens = list(set(''.join(smiles)))\n",
        "        tokens = list(np.sort(tokens))\n",
        "        tokens = ''.join(tokens)\n",
        "    token2idx = dict((token, i) for i, token in enumerate(tokens))\n",
        "    num_tokens = len(tokens)\n",
        "    return tokens, token2idx, num_tokens\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "aHuSouDGYyie",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def time_since(since):\n",
        "    s = time.time() - since\n",
        "    m = math.floor(s / 60)\n",
        "    s -= m * 60\n",
        "    return '%dm %ds' % (m, s)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "3nBYgIEJYw_n",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def cross_validation_split(x, y, n_folds=5, split='random', folds=None):\n",
        "    assert(len(x) == len(y))\n",
        "    x = np.array(x)\n",
        "    y = np.array(y)\n",
        "    if split not in ['random', 'stratified', 'fixed']:\n",
        "        raise ValueError('Invalid value for argument \\'split\\': '\n",
        "                         'must be either \\'random\\', \\'stratified\\' '\n",
        "                         'or \\'fixed\\'')\n",
        "    if split == 'random':\n",
        "        cv_split = KFold(n_splits=n_folds, shuffle=True)\n",
        "        folds = list(cv_split.split(x, y))\n",
        "    elif split == 'stratified':\n",
        "        cv_split = StratifiedKFold(n_splits=n_folds, shuffle=True)\n",
        "        folds = list(cv_split.split(x, y))\n",
        "    elif split == 'fixed' and folds is None:\n",
        "        raise TypeError(\n",
        "            'Invalid type for argument \\'folds\\': found None, but must be list')\n",
        "    cross_val_data = []\n",
        "    cross_val_labels = []\n",
        "    if len(folds) == n_folds:\n",
        "        for fold in folds:\n",
        "            cross_val_data.append(x[fold[1]])\n",
        "            cross_val_labels.append(y[fold[1]])\n",
        "    elif len(folds) == len(x) and np.max(folds) == n_folds:\n",
        "        for f in range(n_folds):\n",
        "            left = np.where(folds == f)[0].min()\n",
        "            right = np.where(folds == f)[0].max()\n",
        "            cross_val_data.append(x[left:right + 1])\n",
        "            cross_val_labels.append(y[left:right + 1])\n",
        "\n",
        "    return cross_val_data, cross_val_labels"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "_FBT7ziQY1qx",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def read_object_property_file(path, delimiter=',', cols_to_read=[0, 1],\n",
        "                              keep_header=False):\n",
        "    f = open(path, 'r')\n",
        "    reader = csv.reader(f, delimiter=delimiter)\n",
        "    data_full = np.array(list(reader))\n",
        "    if keep_header:\n",
        "        start_position = 0\n",
        "    else:\n",
        "        start_position = 1\n",
        "    assert len(data_full) > start_position\n",
        "    data = [[] for _ in range(len(cols_to_read))]\n",
        "    for i in range(len(cols_to_read)):\n",
        "        col = cols_to_read[i]\n",
        "        data[i] = data_full[start_position:, col]\n",
        "    f.close()\n",
        "    if len(cols_to_read) == 1:\n",
        "        data = data[0]\n",
        "    return data"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Ytn5MmqbY7lz",
        "colab_type": "text"
      },
      "source": [
        "### **Data Process**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "AIz58LRnZJ9T",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import torch\n",
        "import random\n",
        "import numpy as np"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "erBnpdwiZOqc",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "class GeneratorData(object):\n",
        "    def __init__(self, training_data_path, tokens=None, start_token='<', \n",
        "                 end_token='>', max_len=120, use_cuda=None, **kwargs):\n",
        "\n",
        "        super(GeneratorData, self).__init__()\n",
        "\n",
        "        if 'cols_to_read' not in kwargs:\n",
        "            kwargs['cols_to_read'] = []\n",
        "\n",
        "        data = read_object_property_file(training_data_path,\n",
        "                                                       **kwargs)\n",
        "        self.start_token = start_token\n",
        "        self.end_token = end_token\n",
        "        self.file = []\n",
        "        for i in range(len(data)):\n",
        "            if len(data[i]) <= max_len:\n",
        "                self.file.append(self.start_token + data[i] + self.end_token) \n",
        "        self.file_len = len(self.file)\n",
        "        self.all_characters, self.char2idx, \\\n",
        "        self.n_characters = tokenize(self.file, tokens)\n",
        "        self.use_cuda = use_cuda\n",
        "        if self.use_cuda is None:\n",
        "            self.use_cuda = torch.cuda.is_available()\n",
        "\n",
        "    def load_dictionary(self, tokens, char2idx):\n",
        "        self.all_characters = tokens\n",
        "        self.char2idx = char2idx\n",
        "        self.n_characters = len(tokens)\n",
        "\n",
        "    def random_chunk(self):\n",
        "\n",
        "        index = random.randint(0, self.file_len-1)\n",
        "        return self.file[index]\n",
        "\n",
        "    def char_tensor(self, string):\n",
        "\n",
        "        tensor = torch.zeros(len(string)).long()\n",
        "        for c in range(len(string)):\n",
        "            tensor[c] = self.all_characters.index(string[c])\n",
        "        if self.use_cuda:\n",
        "            return torch.tensor(tensor).cuda()\n",
        "        else:\n",
        "            return torch.tensor(tensor)\n",
        "\n",
        "    def random_training_set(self, smiles_augmentation):\n",
        "        chunk = self.random_chunk()\n",
        "        if smiles_augmentation is not None:\n",
        "            chunk = '<' + smiles_augmentation.randomize_smiles(chunk[1:-1]) + '>'\n",
        "        inp = self.char_tensor(chunk[:-1])\n",
        "        target = self.char_tensor(chunk[1:])\n",
        "        return inp, target\n",
        "\n",
        "    def read_sdf_file(self, path, fields_to_read):\n",
        "        raise NotImplementedError\n",
        "        \n",
        "    def update_data(self, path):\n",
        "        self.file, success = read_smi_file(path, unique=True)\n",
        "        self.file_len = len(self.file)\n",
        "        assert success\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "dyiZIGwfZO0g",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "class PredictorData(object):\n",
        "    def __init__(self, path, delimiter=',', cols=[0, 1], get_features=None,\n",
        "                 has_label=True, labels_start=1, **kwargs):\n",
        "        super(PredictorData, self).__init__()\n",
        "        data = read_object_property_file(path, delimiter, cols_to_read=cols)\n",
        "        if has_label:\n",
        "            self.objects = np.array(data[:labels_start]).reshape(-1)\n",
        "            self.y = np.array(data[labels_start:], dtype='float32')\n",
        "            self.y = self.y.reshape(-1, len(cols) - labels_start)\n",
        "            if self.y.shape[1] == 1:\n",
        "                self.y = self.y.reshape(-1)\n",
        "        else:\n",
        "            self.objects = np.array(data[:labels_start]).reshape(-1)\n",
        "            self.y = [None]*len(self.object)\n",
        "        assert len(self.objects) == len(self.y)\n",
        "        if get_features is not None:\n",
        "            self.x, processed_indices, invalid_indices = \\\n",
        "                get_features(self.objects, **kwargs)\n",
        "            self.invalid_objects = self.objects[invalid_indices]\n",
        "            self.objects = self.objects[processed_indices]\n",
        "            self.invalid_y = self.y[invalid_indices]\n",
        "            self.y = self.y[processed_indices]\n",
        "        else:\n",
        "            self.x = self.objects\n",
        "            self.invalid_objects = None\n",
        "            self.invalid_y = None\n",
        "        self.binary_y = None\n",
        "\n",
        "    def binarize(self, threshold):\n",
        "        self.binary_y = np.array(self.y >= threshold, dtype='int32')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "u3rslGElbhNk",
        "colab_type": "text"
      },
      "source": [
        "### **Smiles Enumerator**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "WJnOHyVCbsTM",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 353
        },
        "outputId": "23494c6e-de78-439a-d051-f8b87bfdbd3b"
      },
      "source": [
        "from rdkit import Chem\n",
        "import numpy as np\n",
        "import threading"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "error",
          "ename": "ModuleNotFoundError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mModuleNotFoundError\u001b[0m                       Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-131-0c469338e13c>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0;32mfrom\u001b[0m \u001b[0mrdkit\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mChem\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      2\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mnumpy\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mthreading\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mModuleNotFoundError\u001b[0m: No module named 'rdkit'",
            "",
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0;32m\nNOTE: If your import is failing due to a missing package, you can\nmanually install dependencies using either !pip or !apt.\n\nTo view examples of installing some common dependencies, click the\n\"Open Examples\" button below.\n\u001b[0;31m---------------------------------------------------------------------------\u001b[0m\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "3uzmFW7nbsjD",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "class Iterator(object):\n",
        "    \"\"\"Abstract base class for data iterators.\n",
        "    # Arguments\n",
        "        n: Integer, total number of samples in the dataset to loop over.\n",
        "        batch_size: Integer, size of a batch.\n",
        "        shuffle: Boolean, whether to shuffle the data between epochs.\n",
        "        seed: Random seeding for data shuffling.\n",
        "    \"\"\"\n",
        "\n",
        "    def __init__(self, n, batch_size, shuffle, seed):\n",
        "        self.n = n\n",
        "        self.batch_size = batch_size\n",
        "        self.shuffle = shuffle\n",
        "        self.batch_index = 0\n",
        "        self.total_batches_seen = 0\n",
        "        self.lock = threading.Lock()\n",
        "        self.index_generator = self._flow_index(n, batch_size, shuffle, seed)\n",
        "        if n < batch_size:\n",
        "            raise ValueError('Input data length is shorter than batch_size\\nAdjust batch_size')\n",
        "\n",
        "    def reset(self):\n",
        "        self.batch_index = 0\n",
        "\n",
        "    def _flow_index(self, n, batch_size=32, shuffle=False, seed=None):\n",
        "        # Ensure self.batch_index is 0.\n",
        "        self.reset()\n",
        "        while 1:\n",
        "            if seed is not None:\n",
        "                np.random.seed(seed + self.total_batches_seen)\n",
        "            if self.batch_index == 0:\n",
        "                index_array = np.arange(n)\n",
        "                if shuffle:\n",
        "                    index_array = np.random.permutation(n)\n",
        "\n",
        "            current_index = (self.batch_index * batch_size) % n\n",
        "            if n > current_index + batch_size:\n",
        "                current_batch_size = batch_size\n",
        "                self.batch_index += 1\n",
        "            else:\n",
        "                current_batch_size = n - current_index\n",
        "                self.batch_index = 0\n",
        "            self.total_batches_seen += 1\n",
        "            yield (index_array[current_index: current_index + current_batch_size],\n",
        "                   current_index, current_batch_size)\n",
        "\n",
        "    def __iter__(self):\n",
        "        # Needed if we want to do something like:\n",
        "        # for x, y in data_gen.flow(...):\n",
        "        return self\n",
        "\n",
        "    def __next__(self, *args, **kwargs):\n",
        "        return self.next(*args, **kwargs)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "HlMnsIfabsnN",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "class SmilesIterator(Iterator):\n",
        "    \"\"\"Iterator yielding data from a SMILES array.\n",
        "    # Arguments\n",
        "        x: Numpy array of SMILES input data.\n",
        "        y: Numpy array of targets data.\n",
        "        smiles_data_generator: Instance of `SmilesEnumerator`\n",
        "            to use for random SMILES generation.\n",
        "        batch_size: Integer, size of a batch.\n",
        "        shuffle: Boolean, whether to shuffle the data between epochs.\n",
        "        seed: Random seed for data shuffling.\n",
        "        dtype: dtype to use for returned batch. Set to keras.backend.floatx if using Keras\n",
        "    \"\"\"\n",
        "\n",
        "    def __init__(self, x, y, smiles_data_generator,\n",
        "                 batch_size=32, shuffle=False, seed=None,\n",
        "                 dtype=np.float32\n",
        "                 ):\n",
        "        if y is not None and len(x) != len(y):\n",
        "            raise ValueError('X (images tensor) and y (labels) '\n",
        "                             'should have the same length. '\n",
        "                             'Found: X.shape = %s, y.shape = %s' %\n",
        "                             (np.asarray(x).shape, np.asarray(y).shape))\n",
        "\n",
        "        self.x = np.asarray(x)\n",
        "\n",
        "        if y is not None:\n",
        "            self.y = np.asarray(y)\n",
        "        else:\n",
        "            self.y = None\n",
        "        self.smiles_data_generator = smiles_data_generator\n",
        "        self.dtype = dtype\n",
        "        super(SmilesIterator, self).__init__(x.shape[0], batch_size, shuffle, seed)\n",
        "\n",
        "    def next(self):\n",
        "        \"\"\"For python 2.x.\n",
        "        # Returns\n",
        "            The next batch.\n",
        "        \"\"\"\n",
        "        # Keeps under lock only the mechanism which advances\n",
        "        # the indexing of each batch.\n",
        "        with self.lock:\n",
        "            index_array, current_index, current_batch_size = next(self.index_generator)\n",
        "        # The transformation of images is not under thread lock\n",
        "        # so it can be done in parallel\n",
        "        batch_x = np.zeros(\n",
        "            tuple([current_batch_size] + [self.smiles_data_generator.pad, self.smiles_data_generator._charlen]),\n",
        "            dtype=self.dtype)\n",
        "        for i, j in enumerate(index_array):\n",
        "            smiles = self.x[j:j + 1]\n",
        "            x = self.smiles_data_generator.transform(smiles)\n",
        "            batch_x[i] = x\n",
        "\n",
        "        if self.y is None:\n",
        "            return batch_x\n",
        "        batch_y = self.y[index_array]\n",
        "        return batch_x, batch_y"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "LTXrGNyDbsgm",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 395
        },
        "outputId": "b8a21d82-94e1-41d7-db46-b7f65a769e4e"
      },
      "source": [
        "class SmilesEnumerator(object):\n",
        "    \"\"\"SMILES Enumerator, vectorizer and devectorizer\n",
        "    #Arguments\n",
        "        charset: string containing the characters for the vectorization\n",
        "          can also be generated via the .fit() method\n",
        "        pad: Length of the vectorization\n",
        "        leftpad: Add spaces to the left of the SMILES\n",
        "        isomericSmiles: Generate SMILES containing information about stereogenic centers\n",
        "        enum: Enumerate the SMILES during transform\n",
        "        canonical: use canonical SMILES during transform (overrides enum)\n",
        "    \"\"\"\n",
        "\n",
        "    def __init__(self, charset='@C)(=cOn1S2/H[N]\\\\', pad=120, leftpad=True, isomericSmiles=True, enum=True,\n",
        "                 canonical=False):\n",
        "        self._charset = None\n",
        "        self.charset = charset\n",
        "        self.pad = pad\n",
        "        self.leftpad = leftpad\n",
        "        self.isomericSmiles = isomericSmiles\n",
        "        self.enumerate = enum\n",
        "        self.canonical = canonical\n",
        "\n",
        "    @property\n",
        "    def charset(self):\n",
        "        return self._charset\n",
        "\n",
        "    @charset.setter\n",
        "    def charset(self, charset):\n",
        "        self._charset = charset\n",
        "        self._charlen = len(charset)\n",
        "        self._char_to_int = dict((c, i) for i, c in enumerate(charset))\n",
        "        self._int_to_char = dict((i, c) for i, c in enumerate(charset))\n",
        "\n",
        "    def fit(self, smiles, extra_chars=[], extra_pad=5):\n",
        "        \"\"\"Performs extraction of the charset and length of a SMILES datasets and sets self.pad and self.charset\n",
        "        #Arguments\n",
        "            smiles: Numpy array or Pandas series containing smiles as strings\n",
        "            extra_chars: List of extra chars to add to the charset (e.g. \"\\\\\\\\\" when \"/\" is present)\n",
        "            extra_pad: Extra padding to add before or after the SMILES vectorization\n",
        "        \"\"\"\n",
        "        charset = set(\"\".join(list(smiles)))\n",
        "        self.charset = \"\".join(charset.union(set(extra_chars)))\n",
        "        self.pad = max([len(smile) for smile in smiles]) + extra_pad\n",
        "\n",
        "    def randomize_smiles(self, smiles):\n",
        "        \"\"\"Perform a randomization of a SMILES string\n",
        "        must be RDKit sanitizable\"\"\"\n",
        "        m = Chem.MolFromSmiles(smiles)\n",
        "        ans = list(range(m.GetNumAtoms()))\n",
        "        np.random.shuffle(ans)\n",
        "        nm = Chem.RenumberAtoms(m, ans)\n",
        "        return Chem.MolToSmiles(nm, canonical=self.canonical, isomericSmiles=self.isomericSmiles)\n",
        "\n",
        "    def transform(self, smiles):\n",
        "        \"\"\"Perform an enumeration (randomization) and vectorization of a Numpy array of smiles strings\n",
        "        #Arguments\n",
        "            smiles: Numpy array or Pandas series containing smiles as strings\n",
        "        \"\"\"\n",
        "        one_hot = np.zeros((smiles.shape[0], self.pad, self._charlen), dtype=np.int8)\n",
        "\n",
        "        for i, ss in enumerate(smiles):\n",
        "            if self.enumerate: ss = self.randomize_smiles(ss)\n",
        "            for j, c in enumerate(ss):\n",
        "                one_hot[i, j, self._char_to_int[c]] = 1\n",
        "        return one_hot\n",
        "\n",
        "    def reverse_transform(self, vect):\n",
        "        \"\"\" Performs a conversion of a vectorized SMILES to a smiles strings\n",
        "        charset must be the same as used for vectorization.\n",
        "        #Arguments\n",
        "            vect: Numpy array of vectorized SMILES.\n",
        "        \"\"\"\n",
        "        smiles = []\n",
        "        for v in vect:\n",
        "            # mask v\n",
        "            v = v[v.sum(axis=1) == 1]\n",
        "            # Find one hot encoded index with argmax, translate to char and join to string\n",
        "            smile = \"\".join(self._int_to_char[i] for i in v.argmax(axis=1))\n",
        "            smiles.append(smile)\n",
        "        return np.array(smiles)\n",
        "\n",
        "\n",
        "if __name__ == \"__main__\":\n",
        "    smiles = np.array([\"CCC(=O)O[C@@]1(CC[NH+](C[C@H]1CC=C)C)c2ccccc2\",\n",
        "                       \"CCC[S@@](=O)c1ccc2c(c1)[nH]/c(=N/C(=O)OC)/[nH]2\"] * 10\n",
        "                      )\n",
        "    # Test canonical SMILES vectorization\n",
        "    sm_en = SmilesEnumerator(canonical=True, enum=False)\n",
        "    sm_en.fit(smiles, extra_chars=[\"\\\\\"])\n",
        "    v = sm_en.transform(smiles)\n",
        "    transformed = sm_en.reverse_transform(v)\n",
        "    if len(set(transformed)) > 2: print(\"Too many different canonical SMILES generated\")\n",
        "\n",
        "    # Test enumeration\n",
        "    sm_en.canonical = False\n",
        "    sm_en.enumerate = True\n",
        "    v2 = sm_en.transform(smiles)\n",
        "    transformed = sm_en.reverse_transform(v2)\n",
        "    if len(set(transformed)) < 3: print(\"Too few enumerated SMILES generated\")\n",
        "\n",
        "    # Reconstruction\n",
        "    reconstructed = sm_en.reverse_transform(v[0:5])\n",
        "    for i, smile in enumerate(reconstructed):\n",
        "        if smile != smiles[i]:\n",
        "            print(\"Error in reconstruction %s %s\" % (smile, smiles[i]))\n",
        "            break\n",
        "\n",
        "    # test Pandas\n",
        "    import pandas as pd\n",
        "\n",
        "    df = pd.DataFrame(smiles)\n",
        "    v = sm_en.transform(df[0])\n",
        "    if v.shape != (20, 52, 18): print(\"Possible error in pandas use\")\n",
        "\n",
        "    # BUG, when batchsize > x.shape[0], then it only returns x.shape[0]!\n",
        "    # Test batch generation\n",
        "    sm_it = SmilesIterator(smiles, np.array([1, 2] * 10), sm_en, batch_size=10, shuffle=True)\n",
        "    X, y = sm_it.next()\n",
        "    if sum(y == 1) - sum(y == 2) > 1:\n",
        "        print(\"Unbalanced generation of batches\")\n",
        "    if len(X) != 10: print(\"Error in batchsize generation\")"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "error",
          "ename": "NameError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-132-4bb17f75d8d3>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     95\u001b[0m     \u001b[0msm_en\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcanonical\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mFalse\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     96\u001b[0m     \u001b[0msm_en\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0menumerate\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mTrue\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 97\u001b[0;31m     \u001b[0mv2\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0msm_en\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtransform\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msmiles\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     98\u001b[0m     \u001b[0mtransformed\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0msm_en\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mreverse_transform\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mv2\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     99\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mset\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtransformed\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m<\u001b[0m \u001b[0;36m3\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"Too few enumerated SMILES generated\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m<ipython-input-132-4bb17f75d8d3>\u001b[0m in \u001b[0;36mtransform\u001b[0;34m(self, smiles)\u001b[0m\n\u001b[1;32m     60\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     61\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0mi\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mss\u001b[0m \u001b[0;32min\u001b[0m \u001b[0menumerate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msmiles\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 62\u001b[0;31m             \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0menumerate\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mss\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrandomize_smiles\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mss\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     63\u001b[0m             \u001b[0;32mfor\u001b[0m \u001b[0mj\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mc\u001b[0m \u001b[0;32min\u001b[0m \u001b[0menumerate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mss\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     64\u001b[0m                 \u001b[0mone_hot\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mj\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_char_to_int\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mc\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m<ipython-input-132-4bb17f75d8d3>\u001b[0m in \u001b[0;36mrandomize_smiles\u001b[0;34m(self, smiles)\u001b[0m\n\u001b[1;32m     46\u001b[0m         \"\"\"Perform a randomization of a SMILES string\n\u001b[1;32m     47\u001b[0m         must be RDKit sanitizable\"\"\"\n\u001b[0;32m---> 48\u001b[0;31m         \u001b[0mm\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mChem\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mMolFromSmiles\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msmiles\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     49\u001b[0m         \u001b[0mans\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mlist\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mrange\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mm\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mGetNumAtoms\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     50\u001b[0m         \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrandom\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshuffle\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mans\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mNameError\u001b[0m: name 'Chem' is not defined"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ENGjmE2cbLLW",
        "colab_type": "text"
      },
      "source": [
        "### **StackRNN Code**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "WxroIzrCbKT_",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import torch\n",
        "import torch.nn as nn\n",
        "from torch.autograd import Variable\n",
        "import torch.nn.functional as F\n",
        "\n",
        "import time\n",
        "from tqdm import trange"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "s6Z8nXXTcAmX",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "class StackAugmentedRNN(nn.Module):\n",
        "    def __init__(self, input_size, hidden_size, output_size, layer_type='GRU',\n",
        "                 n_layers=1, is_bidirectional=False, has_stack=False,\n",
        "                 stack_width=None, stack_depth=None, use_cuda=None,\n",
        "                 optimizer_instance=torch.optim.Adadelta, lr=0.01):\n",
        "        \"\"\"\n",
        "        Constructor for the StackAugmentedRNN object.\n",
        "        Parameters\n",
        "        ----------\n",
        "        input_size: int\n",
        "            number of characters in the alphabet\n",
        "        hidden_size: int\n",
        "            size of the RNN layer(s)\n",
        "        output_size: int\n",
        "            again number of characters in the alphabet\n",
        "        layer_type: str (default 'GRU')\n",
        "            type of the RNN layer to be used. Could be either 'LSTM' or 'GRU'.\n",
        "        n_layers: int (default 1)\n",
        "            number of RNN layers\n",
        "        is_bidirectional: bool (default False)\n",
        "            parameter specifying if RNN is bidirectional\n",
        "        has_stack: bool (default False)\n",
        "            parameter specifying if augmented memory stack is used\n",
        "        stack_width: int (default None)\n",
        "            if has_stack is True then this parameter defines width of the\n",
        "            augmented stack memory\n",
        "        stack_depth: int (default None)\n",
        "            if has_stack is True then this parameter define depth of the augmented\n",
        "            stack memory. Hint: no need fo stack depth to be larger than the\n",
        "            length of the longest sequence you plan to generate\n",
        "        use_cuda: bool (default None)\n",
        "            parameter specifying if GPU is used for computations. If left\n",
        "            unspecified, GPU will be used if available\n",
        "        optimizer_instance: torch.optim object (default torch.optim.Adadelta)\n",
        "            optimizer to be used for training\n",
        "        lr: float (default 0.01)\n",
        "            learning rate for the optimizer\n",
        "        \"\"\"\n",
        "        super(StackAugmentedRNN, self).__init__()\n",
        "        \n",
        "        if layer_type not in ['GRU', 'LSTM']:\n",
        "            raise InvalidArgumentError('Layer type must be GRU or LSTM')\n",
        "        self.layer_type = layer_type\n",
        "        self.is_bidirectional = is_bidirectional\n",
        "        if self.is_bidirectional:\n",
        "            self.num_dir = 2\n",
        "        else:\n",
        "            self.num_dir = 1\n",
        "        if layer_type == 'LSTM':\n",
        "            self.has_cell = True\n",
        "        else:\n",
        "            self.has_cell = False\n",
        "        self.has_stack = has_stack\n",
        "        self.input_size = input_size\n",
        "        self.hidden_size = hidden_size\n",
        "        self.output_size = output_size\n",
        "        if self.has_stack:\n",
        "            self.stack_width = stack_width\n",
        "            self.stack_depth = stack_depth\n",
        "\n",
        "        self.use_cuda = use_cuda\n",
        "        if self.use_cuda is None:\n",
        "            self.use_cuda = torch.cuda.is_available()\n",
        "\n",
        "        self.n_layers = n_layers\n",
        "        \n",
        "        if self.has_stack:\n",
        "            self.stack_controls_layer = nn.Linear(in_features=self.hidden_size *\n",
        "                                                              self.num_dir,\n",
        "                                                  out_features=3)\n",
        "\n",
        "            self.stack_input_layer = nn.Linear(in_features=self.hidden_size *\n",
        "                                                           self.num_dir,\n",
        "                                               out_features=self.stack_width)\n",
        "\n",
        "        self.encoder = nn.Embedding(input_size, hidden_size)\n",
        "        if self.has_stack:\n",
        "            rnn_input_size = hidden_size + stack_width\n",
        "        else:\n",
        "            rnn_input_size = hidden_size\n",
        "        if self.layer_type == 'LSTM':\n",
        "            self.rnn = nn.LSTM(rnn_input_size, hidden_size, n_layers,\n",
        "                               bidirectional=self.is_bidirectional)\n",
        "            self.decoder = nn.Linear(hidden_size * self.num_dir, output_size)\n",
        "        elif self.layer_type == 'GRU':\n",
        "            self.rnn = nn.GRU(rnn_input_size, hidden_size, n_layers,\n",
        "                             bidirectional=self.is_bidirectional)\n",
        "            self.decoder = nn.Linear(hidden_size * self.num_dir, output_size)\n",
        "        self.log_softmax = torch.nn.LogSoftmax(dim=1)\n",
        "        \n",
        "        if self.use_cuda:\n",
        "            self = self.cuda()\n",
        "        self.criterion = nn.CrossEntropyLoss()\n",
        "        self.lr = lr\n",
        "        self.optimizer_instance = optimizer_instance\n",
        "        self.optimizer = self.optimizer_instance(self.parameters(), lr=lr,\n",
        "                                                 weight_decay=0.00001)\n",
        "  \n",
        "    def load_model(self, path):\n",
        "        \"\"\"\n",
        "        Loads pretrained parameters from the checkpoint into the model.\n",
        "        Parameters\n",
        "        ----------\n",
        "        path: str\n",
        "            path to the checkpoint file model will be loaded from.\n",
        "        \"\"\"\n",
        "        weights = torch.load(path)\n",
        "        self.load_state_dict(weights)\n",
        "\n",
        "    def save_model(self, path):\n",
        "        \"\"\"\n",
        "        Saves model parameters into the checkpoint file.\n",
        "        Parameters\n",
        "        ----------\n",
        "        path: str\n",
        "            path to the checkpoint file model will be saved to.\n",
        "        \"\"\"\n",
        "        torch.save(self.state_dict(), path)\n",
        "\n",
        "    def change_lr(self, new_lr):\n",
        "        \"\"\"\n",
        "        Updates learning rate of the optimizer.\n",
        "        Parameters\n",
        "        ----------\n",
        "        new_lr: float\n",
        "            new learning rate value\n",
        "        \"\"\"\n",
        "        self.optimizer = self.optimizer_instance(self.parameters(), lr=new_lr)\n",
        "        self.lr = new_lr\n",
        "\n",
        "    def forward(self, inp, hidden, stack):\n",
        "        \"\"\"\n",
        "        Forward step of the model. Generates probability of the next character\n",
        "        given the prefix.\n",
        "        Parameters\n",
        "        ----------\n",
        "        inp: torch.tensor\n",
        "            input tensor that contains prefix string indices\n",
        "        hidden: torch.tensor or tuple(torch.tensor, torch.tensor)\n",
        "            previous hidden state of the model. If layer_type is 'LSTM',\n",
        "            then hidden is a tuple of hidden state and cell state, otherwise\n",
        "            hidden is torch.tensor\n",
        "        stack: torch.tensor\n",
        "            previous state of the augmented memory stack\n",
        "        Returns\n",
        "        -------\n",
        "        output: torch.tensor\n",
        "            tensor with non-normalized probabilities of the next character\n",
        "        next_hidden: torch.tensor or tuple(torch.tensor, torch.tensor)\n",
        "            next hidden state of the model. If layer_type is 'LSTM',\n",
        "            then next_hidden is a tuple of hidden state and cell state,\n",
        "            otherwise next_hidden is torch.tensor\n",
        "        next_stack: torch.tensor\n",
        "            next state of the augmented memory stack\n",
        "        \"\"\"\n",
        "        inp = self.encoder(inp.view(1, -1))\n",
        "        if self.has_stack:\n",
        "            if self.has_cell:\n",
        "                hidden_ = hidden[0]\n",
        "            else:\n",
        "                hidden_ = hidden\n",
        "            if self.is_bidirectional:\n",
        "                hidden_2_stack = torch.cat((hidden_[0], hidden_[1]), dim=1)\n",
        "            else:\n",
        "                hidden_2_stack = hidden_.squeeze(0)\n",
        "            stack_controls = self.stack_controls_layer(hidden_2_stack)\n",
        "            stack_controls = F.softmax(stack_controls, dim=1)\n",
        "            stack_input = self.stack_input_layer(hidden_2_stack.unsqueeze(0))\n",
        "            stack_input = torch.tanh(stack_input)\n",
        "            stack = self.stack_augmentation(stack_input.permute(1, 0, 2),\n",
        "                                            stack, stack_controls)\n",
        "            stack_top = stack[:, 0, :].unsqueeze(0)\n",
        "            inp = torch.cat((inp, stack_top), dim=2)\n",
        "        output, next_hidden = self.rnn(inp.view(1, 1, -1), hidden)\n",
        "        output = self.decoder(output.view(1, -1))\n",
        "        return output, next_hidden, stack\n",
        "\n",
        "    def stack_augmentation(self, input_val, prev_stack, controls):\n",
        "        \"\"\"\n",
        "        Augmentation of the tensor into the stack. For more details see\n",
        "        https://arxiv.org/abs/1503.01007\n",
        "        Parameters\n",
        "        ----------\n",
        "        input_val: torch.tensor\n",
        "            tensor to be added to stack\n",
        "        prev_stack: torch.tensor\n",
        "            previous stack state\n",
        "        controls: torch.tensor\n",
        "            predicted probabilities for each operation in the stack, i.e\n",
        "            PUSH, POP and NO_OP. Again, see https://arxiv.org/abs/1503.01007\n",
        "        Returns\n",
        "        -------\n",
        "        new_stack: torch.tensor\n",
        "            new stack state\n",
        "        \"\"\"\n",
        "        batch_size = prev_stack.size(0)\n",
        "\n",
        "        controls = controls.view(-1, 3, 1, 1)\n",
        "        zeros_at_the_bottom = torch.zeros(batch_size, 1, self.stack_width)\n",
        "        if self.use_cuda:\n",
        "            zeros_at_the_bottom = Variable(zeros_at_the_bottom.cuda())\n",
        "        else:\n",
        "            zeros_at_the_bottom = Variable(zeros_at_the_bottom)\n",
        "        a_push, a_pop, a_no_op = controls[:, 0], controls[:, 1], controls[:, 2]\n",
        "        stack_down = torch.cat((prev_stack[:, 1:], zeros_at_the_bottom), dim=1)\n",
        "        stack_up = torch.cat((input_val, prev_stack[:, :-1]), dim=1)\n",
        "        new_stack = a_no_op * prev_stack + a_push * stack_up + a_pop * stack_down\n",
        "        return new_stack\n",
        "\n",
        "    def init_hidden(self):\n",
        "        \"\"\"\n",
        "        Initialization of the hidden state of RNN.\n",
        "        Returns\n",
        "        -------\n",
        "        hidden: torch.tensor\n",
        "            tensor filled with zeros of an appropriate size (taking into\n",
        "            account number of RNN layers and directions)\n",
        "        \"\"\"\n",
        "        if self.use_cuda:\n",
        "            return Variable(torch.zeros(self.n_layers * self.num_dir, 1,\n",
        "                                        self.hidden_size).cuda())\n",
        "        else:\n",
        "            return Variable(torch.zeros(self.n_layers * self.num_dir, 1,\n",
        "                                        self.hidden_size))\n",
        "\n",
        "    def init_cell(self):\n",
        "        \"\"\"\n",
        "        Initialization of the cell state of LSTM. Only used when layers_type is\n",
        "        'LSTM'\n",
        "        Returns\n",
        "        -------\n",
        "        cell: torch.tensor\n",
        "            tensor filled with zeros of an appropriate size (taking into\n",
        "            account number of RNN layers and directions)\n",
        "        \"\"\"\n",
        "        if self.use_cuda:\n",
        "            return Variable(torch.zeros(self.n_layers * self.num_dir, 1,\n",
        "                                        self.hidden_size).cuda())\n",
        "        else:\n",
        "            return Variable(torch.zeros(self.n_layers * self.num_dir, 1,\n",
        "                                        self.hidden_size))\n",
        "\n",
        "    def init_stack(self):\n",
        "        \"\"\"\n",
        "        Initialization of the stack state. Only used when has_stack is True\n",
        "        Returns\n",
        "        -------\n",
        "        stack: torch.tensor\n",
        "            tensor filled with zeros\n",
        "        \"\"\"\n",
        "        result = torch.zeros(1, self.stack_depth, self.stack_width)\n",
        "        if self.use_cuda:\n",
        "            return Variable(result.cuda())\n",
        "        else:\n",
        "            return Variable(result)\n",
        "\n",
        "    def train_step(self, inp, target):\n",
        "        \"\"\"\n",
        "        One train step, i.e. forward-backward and parameters update, for\n",
        "        a single training example.\n",
        "        Parameters\n",
        "        ----------\n",
        "        inp: torch.tensor\n",
        "            tokenized training string from position 0 to position (seq_len - 1)\n",
        "        target:\n",
        "            tokenized training string from position 1 to position seq_len\n",
        "        Returns\n",
        "        -------\n",
        "        loss: float\n",
        "            mean value of the loss function (averaged through the sequence\n",
        "            length)\n",
        "        \"\"\"\n",
        "        hidden = self.init_hidden()\n",
        "        if self.has_cell:\n",
        "            cell = self.init_cell()\n",
        "            hidden = (hidden, cell)\n",
        "        if self.has_stack:\n",
        "            stack = self.init_stack()\n",
        "        else:\n",
        "            stack = None\n",
        "        self.optimizer.zero_grad()\n",
        "        loss = 0\n",
        "        for c in range(len(inp)):\n",
        "            output, hidden, stack = self(inp[c], hidden, stack)\n",
        "            loss += self.criterion(output, target[c].unsqueeze(0))\n",
        "\n",
        "        loss.backward()\n",
        "        self.optimizer.step()\n",
        "\n",
        "        return loss.item() / len(inp)\n",
        "    \n",
        "    def evaluate(self, data, prime_str='<', end_token='>', predict_len=100):\n",
        "        \"\"\"\n",
        "        Generates new string from the model distribution.\n",
        "        Parameters\n",
        "        ----------\n",
        "        data: object of type GeneratorData\n",
        "            stores information about the generator data format such alphabet, etc\n",
        "        prime_str: str (default '<')\n",
        "            prime string that will be used as prefix. Deafult value is just the\n",
        "            START_TOKEN\n",
        "        end_token: str (default '>')\n",
        "            when end_token is sampled from the model distribution,\n",
        "            the generation of a new example is finished\n",
        "        predict_len: int (default 100)\n",
        "            maximum length of the string to be generated. If the end_token is\n",
        "            not sampled, the generation will be aborted when the length of the\n",
        "            generated sequence is equal to predict_len\n",
        "        Returns\n",
        "        -------\n",
        "        new_sample: str\n",
        "            Newly generated sample from the model distribution.\n",
        "        \"\"\"\n",
        "        hidden = self.init_hidden()\n",
        "        if self.has_cell:\n",
        "            cell = self.init_cell()\n",
        "            hidden = (hidden, cell)\n",
        "        if self.has_stack:\n",
        "            stack = self.init_stack()\n",
        "        else:\n",
        "            stack = None\n",
        "        prime_input = data.char_tensor(prime_str)\n",
        "        new_sample = prime_str\n",
        "\n",
        "        # Use priming string to \"build up\" hidden state\n",
        "        for p in range(len(prime_str)-1):\n",
        "            _, hidden, stack = self.forward(prime_input[p], hidden, stack)\n",
        "        inp = prime_input[-1]\n",
        "\n",
        "        for p in range(predict_len):\n",
        "            output, hidden, stack = self.forward(inp, hidden, stack)\n",
        "\n",
        "            # Sample from the network as a multinomial distribution\n",
        "            probs = torch.softmax(output, dim=1)\n",
        "            top_i = torch.multinomial(probs.view(-1), 1)[0].cpu().numpy()\n",
        "\n",
        "            # Add predicted character to string and use as next input\n",
        "            predicted_char = data.all_characters[top_i]\n",
        "            new_sample += predicted_char\n",
        "            inp = data.char_tensor(predicted_char)\n",
        "            if predicted_char == end_token:\n",
        "                break\n",
        "\n",
        "        return new_sample\n",
        "\n",
        "    def fit(self, data, n_iterations, all_losses=[], print_every=100,\n",
        "            plot_every=10, augment=False):\n",
        "        \"\"\"\n",
        "        This methods fits the parameters of the model. Training is performed to\n",
        "        minimize the cross-entropy loss when predicting the next character\n",
        "        given the prefix.\n",
        "        Parameters\n",
        "        ----------\n",
        "        data: object of type GeneratorData\n",
        "            stores information about the generator data format such alphabet, etc\n",
        "        n_iterations: int\n",
        "            how many iterations of training will be performed\n",
        "        all_losses: list (default [])\n",
        "            list to store the values of the loss function\n",
        "        print_every: int (default 100)\n",
        "            feedback will be printed to std_out once every print_every\n",
        "            iterations of training\n",
        "        plot_every: int (default 10)\n",
        "            value of the loss function will be appended to all_losses once every\n",
        "            plot_every iterations of training\n",
        "        augment: bool (default False)\n",
        "            parameter specifying if SMILES enumeration will be used. For mode\n",
        "            details on SMILES enumeration see https://arxiv.org/abs/1703.07076\n",
        "        Returns\n",
        "        -------\n",
        "        all_losses: list\n",
        "            list that stores the values of the loss function (learning curve)\n",
        "        \"\"\"\n",
        "        start = time.time()\n",
        "        loss_avg = 0\n",
        "\n",
        "        if augment:\n",
        "            smiles_augmentation = SmilesEnumerator()\n",
        "        else:\n",
        "            smiles_augmentation = None\n",
        "\n",
        "        for epoch in trange(1, n_iterations + 1, desc='Training in progress...'):\n",
        "            inp, target = data.random_training_set(smiles_augmentation)\n",
        "            loss = self.train_step(inp, target)\n",
        "            loss_avg += loss\n",
        "\n",
        "            if epoch % print_every == 0:\n",
        "                print('[%s (%d %d%%) %.4f]' % (time_since(start), epoch,\n",
        "                                               epoch / n_iterations * 100, loss)\n",
        "                      )\n",
        "                print(self.evaluate(data=data, prime_str = '<',\n",
        "                                    predict_len=100), '\\n')\n",
        "\n",
        "            if epoch % plot_every == 0:\n",
        "                all_losses.append(loss_avg / plot_every)\n",
        "                loss_avg = 0\n",
        "        return all_losses"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "uBwWzIjNhYZ8",
        "colab_type": "text"
      },
      "source": [
        "### **Predictor**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "fcV4gmndhbZe",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from __future__ import print_function\n",
        "from __future__ import division\n",
        "\n",
        "import numpy as np\n",
        "\n",
        "from sklearn.externals import joblib\n",
        "from sklearn import metrics"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "zpV2jo59hcmo",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "class VanillaQSAR(object):\n",
        "    def __init__(self, model_instance=None, model_params=None,\n",
        "                 model_type='classifier', ensemble_size=5, normalization=False):\n",
        "        super(VanillaQSAR, self).__init__()\n",
        "        self.model_instance = model_instance\n",
        "        self.model_params = model_params\n",
        "        self.ensemble_size = ensemble_size\n",
        "        self.model = []\n",
        "        self.normalization = normalization\n",
        "        if model_type not in ['classifier', 'regressor']:\n",
        "            raise InvalidArgumentError(\"model type must be either\"\n",
        "                                       \"classifier or regressor\")\n",
        "        self.model_type = model_type\n",
        "        if isinstance(self.model_instance, list):\n",
        "            assert(len(self.model_instance) == self.ensemble_size)\n",
        "            assert(isinstance(self.model_params, list))\n",
        "            assert(len(self.model_params) == self.ensemble_size)\n",
        "            for i in range(self.ensemble_size):\n",
        "                self.model.append(self.model_instance[i](**model_params[i]))\n",
        "        else:\n",
        "            for _ in range(self.ensemble_size):\n",
        "                self.model.append(self.model_instance(**model_params))\n",
        "        if self.normalization:\n",
        "            self.desc_mean = [0]*self.ensemble_size\n",
        "        self.metrics_type = None\n",
        "\n",
        "    def fit_model(self, data, cv_split='stratified'):\n",
        "        eval_metrics = []\n",
        "        x = data.x\n",
        "        if self.model_type == 'classifier' and data.binary_y is not None:\n",
        "            y = data.binary_y\n",
        "        else:\n",
        "            y = data.y\n",
        "        cross_val_data, cross_val_labels = cross_validation_split(x=x, y=y,\n",
        "                                                                  split=cv_split,\n",
        "                                                                  n_folds=self.ensemble_size)\n",
        "        for i in range(self.ensemble_size):\n",
        "            train_x = np.concatenate(cross_val_data[:i] +\n",
        "                                     cross_val_data[(i + 1):])\n",
        "            test_x = cross_val_data[i]\n",
        "            train_y = np.concatenate(cross_val_labels[:i] +\n",
        "                                     cross_val_labels[(i + 1):])\n",
        "            test_y = cross_val_labels[i]\n",
        "            if self.normalization:\n",
        "                train_x, desc_mean = normalize_desc(train_x)\n",
        "                self.desc_mean[i] = desc_mean\n",
        "                test_x, _ = normalize_desc(test_x, desc_mean)\n",
        "            self.model[i].fit(train_x, train_y.ravel())\n",
        "            predicted = self.model[i].predict(test_x)\n",
        "            if self.model_type == 'classifier':\n",
        "                eval_metrics.append(metrics.f1_score(test_y, predicted))\n",
        "                self.metrics_type = 'F1 score'\n",
        "            elif self.model_type == 'regressor':\n",
        "                r2 = metrics.r2_score(test_y, predicted)\n",
        "                eval_metrics.append(r2)\n",
        "                self.metrics_type = 'R^2 score'\n",
        "            else:\n",
        "                raise RuntimeError()\n",
        "        return eval_metrics, self.metrics_type\n",
        "\n",
        "    def load_model(self, path):\n",
        "        # TODO: add iterable path object instead of static path \n",
        "        self.model = []\n",
        "        for i in range(self.ensemble_size):\n",
        "            m = joblib.load(path + str(i) + '.pkl')\n",
        "            self.model.append(m)\n",
        "        if self.normalization:\n",
        "            arr = np.load(path + 'desc_mean.npy')\n",
        "            self.desc_mean = arr\n",
        "\n",
        "    def save_model(self, path):\n",
        "        assert self.ensemble_size == len(self.model)\n",
        "        for i in range(self.ensemble_size):\n",
        "            joblib.dump(self.model[i], path + str(i) + '.pkl')\n",
        "        if self.normalization:\n",
        "            np.save(path + 'desc_mean.npy', self.desc_mean)\n",
        "\n",
        "    def predict(self, objects=None, average=True, get_features=None,\n",
        "                **kwargs):\n",
        "        objects = objects\n",
        "        invalid_objects = []\n",
        "        processed_objects = []\n",
        "        if get_features is not None:\n",
        "            x, processed_indices, invalid_indices = get_features(objects,\n",
        "                                                                 **kwargs)\n",
        "            processed_objects = objects[processed_indices]\n",
        "            invalid_objects = objects[invalid_indices]\n",
        "        else:\n",
        "            x = objects\n",
        "        if len(x) == 0:\n",
        "            processed_objects = []\n",
        "            prediction = []\n",
        "            invalid_objects = objects\n",
        "        else:\n",
        "            prediction = []\n",
        "            for i in range(self.ensemble_size):\n",
        "                m = self.model[i]\n",
        "                if self.normalization:\n",
        "                    x, _ = normalize_desc(x, self.desc_mean[i])\n",
        "                prediction.append(m.predict(x))\n",
        "            if average:\n",
        "                prediction = prediction.mean(axis=0)\n",
        "        return prediction\n",
        "'''ORIGINAL CODE\n",
        "    def predict(self, objects=None, average=True, get_features=None,\n",
        "                **kwargs):\n",
        "        objects = np.array(objects)\n",
        "        invalid_objects = []\n",
        "        processed_objects = []\n",
        "        if get_features is not None:\n",
        "            x, processed_indices, invalid_indices = get_features(objects,\n",
        "                                                                 **kwargs)\n",
        "            processed_objects = objects[processed_indices]\n",
        "            invalid_objects = objects[invalid_indices]\n",
        "        else:\n",
        "            x = objects\n",
        "        if len(x) == 0:\n",
        "            processed_objects = []\n",
        "            prediction = []\n",
        "            invalid_objects = objects\n",
        "        else:\n",
        "            prediction = []\n",
        "            for i in range(self.ensemble_size):\n",
        "                m = self.model[i]\n",
        "                if self.normalization:\n",
        "                    x, _ = normalize_desc(x, self.desc_mean[i])\n",
        "                prediction.append(m.predict(x))\n",
        "            prediction = np.array(prediction)\n",
        "            if average:\n",
        "                prediction = prediction.mean(axis=0)\n",
        "        return processed_objects, prediction, invalid_objects\n",
        "'''\n",
        "\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "SZxClZHoh84R",
        "colab_type": "text"
      },
      "source": [
        "### **Reinforcement.py**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "OT28fraYiCe9",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import torch\n",
        "import torch.nn.functional as F\n",
        "import numpy as np\n",
        "from rdkit import Chem"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "qlyCXt7piCq7",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "class Reinforcement(object):\n",
        "    def __init__(self, generator, predictor, get_reward):\n",
        "        \"\"\"\n",
        "        Constructor for the Reinforcement object.\n",
        "        Parameters\n",
        "        ----------\n",
        "        generator: object of type StackAugmentedRNN\n",
        "            generative model that produces string of characters (trajectories)\n",
        "        predictor: object of any predictive model type\n",
        "            predictor accepts a trajectory and returns a numerical\n",
        "            prediction of desired property for the given trajectory\n",
        "        get_reward: function\n",
        "            custom reward function that accepts a trajectory, predictor and\n",
        "            any number of positional arguments and returns a single value of\n",
        "            the reward for the given trajectory\n",
        "            Example:\n",
        "            reward = get_reward(trajectory=my_traj, predictor=my_predictor,\n",
        "                                custom_parameter=0.97)\n",
        "        Returns\n",
        "        -------\n",
        "        object of type Reinforcement used for biasing the properties estimated\n",
        "        by the predictor of trajectories produced by the generator to maximize\n",
        "        the custom reward function get_reward.\n",
        "        \"\"\"\n",
        "\n",
        "        super(Reinforcement, self).__init__()\n",
        "        self.generator = generator\n",
        "        self.predictor = predictor\n",
        "        self.get_reward = get_reward\n",
        "\n",
        "    def policy_gradient(self, data, n_batch=10, gamma=0.97,\n",
        "                        std_smiles=False, grad_clipping=None, **kwargs):\n",
        "        \"\"\"\n",
        "        Implementation of the policy gradient algorithm.\n",
        "        Parameters:\n",
        "        -----------\n",
        "        data: object of type GeneratorData\n",
        "            stores information about the generator data format such alphabet, etc\n",
        "        n_batch: int (default 10)\n",
        "            number of trajectories to sample per batch. When training on GPU\n",
        "            setting this parameter to to some relatively big numbers can result\n",
        "            in out of memory error. If you encountered such an error, reduce\n",
        "            n_batch.\n",
        "        gamma: float (default 0.97)\n",
        "            factor by which rewards will be discounted within one trajectory.\n",
        "            Usually this number will be somewhat close to 1.0.\n",
        "        std_smiles: bool (default False)\n",
        "            boolean parameter defining whether the generated trajectories will\n",
        "            be converted to standardized SMILES before running policy gradient.\n",
        "            Leave this parameter to the default value if your trajectories are\n",
        "            not SMILES.\n",
        "        grad_clipping: float (default None)\n",
        "            value of the maximum norm of the gradients. If not specified,\n",
        "            the gradients will not be clipped.\n",
        "        kwargs: any number of other positional arguments required by the\n",
        "            get_reward function.\n",
        "        Returns\n",
        "        -------\n",
        "        total_reward: float\n",
        "            value of the reward averaged through n_batch sampled trajectories\n",
        "        rl_loss: float\n",
        "            value for the policy_gradient loss averaged through n_batch sampled\n",
        "            trajectories\n",
        "        \"\"\"\n",
        "        rl_loss = 0\n",
        "        self.generator.optimizer.zero_grad()\n",
        "        total_reward = 0\n",
        "        \n",
        "        for _ in range(n_batch):\n",
        "\n",
        "            # Sampling new trajectory\n",
        "            reward = 0\n",
        "            trajectory = '<>'\n",
        "            while reward == 0:\n",
        "                trajectory = self.generator.evaluate(data)\n",
        "                if std_smiles:\n",
        "                    try:\n",
        "                        mol = Chem.MolFromSmiles(trajectory[1:-1])\n",
        "                        trajectory = '<' + Chem.MolToSmiles(mol) + '>'\n",
        "                        reward = self.get_reward(trajectory[1:-1], \n",
        "                                                 self.predictor, \n",
        "                                                 **kwargs)\n",
        "                    except:\n",
        "                        reward = 0\n",
        "                else:\n",
        "                    reward = self.get_reward(trajectory[1:-1],\n",
        "                                             self.predictor, \n",
        "                                             **kwargs)\n",
        "\n",
        "            # Converting string of characters into tensor\n",
        "            trajectory_input = data.char_tensor(trajectory)\n",
        "            discounted_reward = reward\n",
        "            total_reward += reward\n",
        "\n",
        "            # Initializing the generator's hidden state\n",
        "            hidden = self.generator.init_hidden()\n",
        "            if self.generator.has_cell:\n",
        "                cell = self.generator.init_cell()\n",
        "                hidden = (hidden, cell)\n",
        "            if self.generator.has_stack:\n",
        "                stack = self.generator.init_stack()\n",
        "            else:\n",
        "                stack = None\n",
        "\n",
        "            # \"Following\" the trajectory and accumulating the loss\n",
        "            for p in range(len(trajectory)-1):\n",
        "                output, hidden, stack = self.generator(trajectory_input[p], \n",
        "                                                       hidden, \n",
        "                                                       stack)\n",
        "                log_probs = F.log_softmax(output, dim=1)\n",
        "                top_i = trajectory_input[p+1]\n",
        "                rl_loss -= (log_probs[0, top_i]*discounted_reward)\n",
        "                discounted_reward = discounted_reward * gamma\n",
        "\n",
        "        # Doing backward pass and parameters update\n",
        "        rl_loss = rl_loss / n_batch\n",
        "        total_reward = total_reward / n_batch\n",
        "        rl_loss.backward()\n",
        "        if grad_clipping is not None:\n",
        "            torch.nn.utils.clip_grad_norm_(self.generator.parameters(), \n",
        "                                           grad_clipping)\n",
        "\n",
        "        self.generator.optimizer.step()\n",
        "        \n",
        "        return total_reward, rl_loss.item()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "_pz3z9t8cKo5",
        "colab_type": "text"
      },
      "source": [
        "### **Maximize JAK2**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "vq_8ZqmocRtZ",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "%load_ext autoreload\n",
        "%autoreload 2"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "_3oSREfCcUJg",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import sys"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "_CDwPiLfcUTY",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "sys.path.append('./release/')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "42hm_7s4cUeE",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import torch\n",
        "import torch.nn as nn\n",
        "from torch.optim.lr_scheduler import ExponentialLR, StepLR\n",
        "import torch.nn.functional as F"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "sydzne8CcUij",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "use_cuda = torch.cuda.is_available()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "r1DAO4N0cUQ4",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import numpy as np\n",
        "from tqdm import tqdm, trange\n",
        "import pickle\n",
        "from rdkit import Chem, DataStructs"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "b6OuTXf3cUOt",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import matplotlib.pyplot as plt\n",
        "%matplotlib inline\n",
        "\n",
        "import seaborn as sns"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "x_ZJsc3Icj1P",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive', force_remount=True)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "qfr-BlyceQFl",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#data for generative model to train stack RNN (1st version of the model)\n",
        "gen_data_path = '/content/drive/My Drive/Synbiolic Files/Datasets for JAK2 Synbiolic/chembl_1mil_dataset.csv'"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "dJx8QKQveIdF",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "tokens = ['<', '>', '#', '%', ')', '(', '+', '-', '/', '.', '1', '0', '3', '2', '5', '4', '7',\n",
        "          '6', '9', '8', '=', 'A', '@', 'C', 'B', 'F', 'I', 'H', 'O', 'N', 'P', 'S', '[', ']',\n",
        "          '\\\\', 'c', 'e', 'i', 'l', 'o', 'n', 'p', 's', 'r', '\\n']"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "c60msUebeNol",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#use data generator - this is the data to train \n",
        "import csv\n",
        "gen_data = GeneratorData(training_data_path=gen_data_path, delimiter='\\t', \n",
        "                         cols_to_read=[0], keep_header=True, tokens=tokens)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "4xNe9waRPEpO",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "prime_str='<'\n",
        "end_token='>'\n",
        "\n",
        "a = gen_data.char_tensor(prime_str)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "1RUSmhjLPulm",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "print(a)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "mmC-vmDBPy0v",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "b = tensor([0], device='cuda:0')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ez-w8paF519A",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "print(gen_data.n_characters)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "bhKEIgiBebSS",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#---------------------------distribution of molecules pre-training----------------------------\n",
        "#-------------------for the stack memory RNN model, we don't have this for VAE :/-----------------------\n",
        "def plot_hist(prediction, n_to_generate):\n",
        "    print(\"Mean value of predictions:\", prediction.mean())\n",
        "    print(\"Proportion of valid SMILES:\", len(prediction)/n_to_generate)\n",
        "    ax = sns.kdeplot(prediction, shade=True)\n",
        "    ax.set(xlabel='Predicted pIC50', \n",
        "           title='Distribution of predicted pIC50 for generated molecules')\n",
        "    plt.show()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "jgkBN6utepVW",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 55
        },
        "outputId": "98c6726a-b6ca-426d-ca3c-79d7c2188873"
      },
      "source": [
        "#estimate update function is used for training - loops through stuff, if reward is greater than expected it back progs a certain way basically \n",
        "'''\n",
        "estimate_and_update function:\n",
        "\n",
        "1) generates n_to_generate number of SMILES strings\n",
        "\n",
        "2) filters invalid SMILES\n",
        "\n",
        "3) predicts pIC50 for valid SMILES\n",
        "\n",
        "4) plots histogram of predicted pIC50\n",
        "\n",
        "5) Returns valid SMILES and their predicted pIC50s\n",
        "'''\n",
        "\n",
        "# revision #1 without canonical smiles\n",
        "def estimate_and_update(generator, predictor, n_to_generate, **kwargs):\n",
        "    generated = []\n",
        "    pbar = tqdm(range(n_to_generate))\n",
        "    for i in pbar:\n",
        "        pbar.set_description(\"Generating molecules...\")\n",
        "        generated.append(generator.evaluate(gen_data, predict_len=120)[1:-1])\n",
        "    unique_smiles = list(np.unique(generated))[1:]\n",
        "    smiles, prediction, nan_smiles = predictor.predict(unique_smiles, get_features=get_fp)  \n",
        "                                                       \n",
        "    plot_hist(prediction, n_to_generate)\n",
        "        \n",
        "    return smiles, prediction\n",
        "\n",
        "''' --- # original v1 function w/ canonical smiles ---\n",
        "def estimate_and_update(generator, predictor, n_to_generate, **kwargs):\n",
        "    generated = []\n",
        "    pbar = tqdm(range(n_to_generate))\n",
        "    for i in pbar:\n",
        "        pbar.set_description(\"Generating molecules...\")\n",
        "        generated.append(generator.evaluate(gen_data, predict_len=120)[1:-1])\n",
        "    #canoical smiles - SMILES string has to be in this format \n",
        "    sanitized = canonical_smiles(generated, sanitize=False, throw_warning=False)[:-1]\n",
        "    unique_smiles = list(np.unique(sanitized))[1:]\n",
        "    smiles, prediction, nan_smiles = predictor.predict(unique_smiles, get_features=get_fp)  \n",
        "                                                       \n",
        "    plot_hist(prediction, n_to_generate)\n",
        "        \n",
        "    return smiles, prediction\n",
        "'''\n",
        "\n",
        "''' --- # revision #2 estimate & update function without predictor RFR model ---\n",
        "def estimate_and_update(generator, n_to_generate, **kwargs):\n",
        "    generated = []\n",
        "    pbar = tqdm(range(n_to_generate))\n",
        "    for i in pbar:\n",
        "        pbar.set_description(\"Generating molecules...\")\n",
        "        generated.append(generator.evaluate(gen_data, predict_len=120)[1:-1])\n",
        "    #canoical smiles - SMILES string has to be in this format \n",
        "    sanitized = canonical_smiles(generated, sanitize=False, throw_warning=False)[:-1]\n",
        "    unique_smiles = list(np.unique(sanitized))[1:]\n",
        "                                                               \n",
        "    return unique_smiles \n",
        "'''\n",
        "\n",
        "''' --- # revision #3 estimate & update function without rdkit dependencies --- \n",
        "def estimate_and_update(generator, n_to_generate, **kwargs):\n",
        "    generated = []\n",
        "    pbar = tqdm(range(n_to_generate))\n",
        "    for i in pbar:\n",
        "        pbar.set_description(\"Generating molecules...\")\n",
        "        generated.append(generator.evaluate(gen_data, predict_len=120)[1:-1])\n",
        "    unique_smiles = list(np.unique(generated))[1:]\n",
        "                                                               \n",
        "    return unique_smiles \n",
        "'''"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'\\n#revision #2 without rdkit dependencies\\ndef estimate_and_update(generator, n_to_generate, **kwargs):\\n    generated = []\\n    pbar = tqdm(range(n_to_generate))\\n    for i in pbar:\\n        pbar.set_description(\"Generating molecules...\")\\n        generated.append(generator.evaluate(gen_data, predict_len=120)[1:-1])\\n    unique_smiles = list(np.unique(generated))[1:]\\n                                                               \\n    return unique_smiles \\n'"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 133
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "WpN-TE8nerY0",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "hidden_size = 1500\n",
        "stack_width = 1500\n",
        "stack_depth = 200\n",
        "layer_type = 'GRU'\n",
        "n_characters = 45\n",
        "lr = 0.001\n",
        "optimizer_instance = torch.optim.Adadelta\n",
        "\n",
        "#------------------stack memory RNN model for generative model----------\n",
        "my_generator = StackAugmentedRNN(input_size=n_characters, hidden_size=hidden_size,\n",
        "                                 output_size=n_characters, layer_type=layer_type,\n",
        "                                 n_layers=1, is_bidirectional=False, has_stack=True,\n",
        "                                 stack_width=stack_width, stack_depth=stack_depth, \n",
        "                                 use_cuda=use_cuda, \n",
        "                                 optimizer_instance=optimizer_instance, lr=lr)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "DlpYsWeKeuZO",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "gen_model_path = \"/content/drive/My Drive/Synbiolic Files/Synbiolic's Generative Platform: Final Saved Models/generative_max_model\" #colab is the max_biased_generative_model --> biggest_rnn is the unbiased_generative_model; change this accordingly"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "FNDpUIADnkjH",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#-----Train model code-----------------------\n",
        "losses = my_generator.fit(gen_data, 1500000)\n",
        "plt.plot(losses)\n",
        "my_generator.evaluate(gen_data)\n",
        "\n",
        "my_generator.save_model(model_path)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "elNUH6p2e7--",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#load the model without training ^ skipping above cell \n",
        "my_generator.load_model(gen_model_path)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "vFmkDhjFfwZf",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "!pip install mordred\n",
        "from mordred import Calculator, descriptors"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "iCpFUbXkgxYu",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "calc = Calculator(descriptors, ignore_3D=True)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "syckk45rgymY",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import csv\n",
        "pred_data = PredictorData(path='/content/drive/My Drive/Synbiolic Files/Datasets for JAK2 Synbiolic/jak2_data.csv', get_features=get_fp)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Dwh42YxcgyyX",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from sklearn.ensemble import RandomForestRegressor as RFR"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "WIeeNd5Lgy9D",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "model_instance = RFR\n",
        "model_params = {'n_estimators': 250, 'n_jobs': 10}"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "YrVtfpBbgzN_",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#my_predict = predictor model \n",
        "my_predictor = VanillaQSAR(model_instance=model_instance,\n",
        "                           model_params=model_params,\n",
        "                           model_type='regressor')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "uF5ag9oggzGe",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "my_predictor.fit_model(pred_data, cv_split='random')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "XCtv7ZYYxBLB",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#only run if you want to save model\n",
        "import pickle\n",
        "\n",
        "filename='predict_model.sav'\n",
        "pickle.dump(my_predictor, open(filename, 'wb'))\n",
        "\n",
        "from google.colab import files\n",
        "files.download('/content/predict_model.sav') "
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ulIrMW3Xy3dj",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#only run to save model \n",
        "from google.colab import files\n",
        "files.download('/content/predict_model.sav') "
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "oH3QjvLFunpd",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import pickle\n",
        "\n",
        "my_predict_path = \"/content/drive/My Drive/Synbiolic Files/Synbiolic's Generative Platform: Final Saved Models/predict_model.sav\"\n",
        "my_predictor = pickle.load(open(my_predict_path, 'rb'))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "NegySOi_hu-8",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# non-essential --> generates unbiased data (data prior to training the models)\n",
        "smiles_unbiased, prediction_unbiased = estimate_and_update(my_generator,\n",
        "                                                           my_predictor,\n",
        "                                                           n_to_generate=100)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Ix0saZ5ehvKa",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#-------------Making a copy of the generator that will be optimized - maximized----------------\n",
        "\n",
        "my_generator_max = StackAugmentedRNN(input_size=gen_data.n_characters, \n",
        "                                     hidden_size=hidden_size,\n",
        "                                     output_size=gen_data.n_characters, \n",
        "                                     layer_type=layer_type,\n",
        "                                     n_layers=1, \n",
        "                                     is_bidirectional=False, \n",
        "                                     has_stack=True,\n",
        "                                     stack_width=stack_width, \n",
        "                                     stack_depth=stack_depth, \n",
        "                                     use_cuda=use_cuda, \n",
        "                                     optimizer_instance=optimizer_instance, \n",
        "                                     lr=lr)\n",
        "\n",
        "my_generator_max.load_model(model_path)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "E5lMz5oYhvWF",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "n_to_generate = 200\n",
        "n_policy_replay = 10\n",
        "n_policy = 15\n",
        "n_iterations = 5"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Wk_RANBAhvgk",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def simple_moving_average(previous_values, new_value, ma_window_size=10):\n",
        "    value_ma = np.sum(previous_values[-(ma_window_size-1):]) + new_value\n",
        "    value_ma = value_ma/(len(previous_values[-(ma_window_size-1):]) + 1)\n",
        "    return value_ma"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "dQIDitH7iUhR",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def get_reward_max(smiles, predictor, invalid_reward=0.0, get_features=get_fp):\n",
        "    mol, prop, nan_smiles = predictor.predict([smiles], get_features=get_features)\n",
        "    if len(nan_smiles) == 1:\n",
        "        return invalid_reward\n",
        "    return np.exp(prop[0]/3)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "2MLt7hKqiWSf",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "x = np.linspace(0, 12)\n",
        "y = np.exp(x/3)\n",
        "plt.plot(x, y)\n",
        "plt.xlabel('pIC50 value')\n",
        "plt.ylabel('Reward value')\n",
        "plt.title('Reward function for JAK2 activity maximization')\n",
        "plt.show()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "sXsaRs7niZGY",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "\"\"\"defining RL model which takes in the generative model, property \n",
        "prediction model & custom reward function\"\"\"\n",
        "RL_max = Reinforcement(my_generator_max, my_predictor, get_reward_max)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "YvH6uVI9iaRx",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "rewards_max = []\n",
        "rl_losses_max = []"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "DAw8jvwXiaaI",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#Training RL model \n",
        "for i in range(n_iterations):\n",
        "    for j in trange(n_policy, desc='Policy gradient...'):\n",
        "        cur_reward, cur_loss = RL_max.policy_gradient(gen_data, \n",
        "                                                      get_features=get_fp)\n",
        "        rewards_max.append(simple_moving_average(rewards_max, cur_reward)) \n",
        "        rl_losses_max.append(simple_moving_average(rl_losses_max, cur_loss))\n",
        "    \n",
        "    plt.plot(rewards_max)\n",
        "    plt.xlabel('Training iteration')\n",
        "    plt.ylabel('Average reward')\n",
        "    plt.show()\n",
        "    plt.plot(rl_losses_max)\n",
        "    plt.xlabel('Training iteration')\n",
        "    plt.ylabel('Loss')\n",
        "    plt.show()\n",
        "  \n",
        "    #Generating new molecules + predict pic50 \n",
        "    smiles_cur, prediction_cur = estimate_and_update(RL_max.generator, \n",
        "                                                     my_predictor, \n",
        "                                                     n_to_generate,\n",
        "                                                     get_features=get_fp)\n",
        "    print('Sample trajectories:')\n",
        "    for sm in smiles_cur[:5]:\n",
        "        print(sm)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "8cwXrb1DkT4J",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#Testing RL model - large number of generate molecules (10 000)\n",
        "smiles_biased_max, prediction_biased_max = estimate_and_update(RL_max.generator, \n",
        "                                                           my_predictor,\n",
        "                                                           n_to_generate=10000)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "RTWTnfKboTZS",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#Testing RL model\n",
        "smiles_biased_max, prediction_biased_max = estimate_and_update(RL_max.generator, \n",
        "                                                           my_predictor,\n",
        "                                                           n_to_generate=100)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "PQJHSDQXiah2",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#----------------DEPLOYING FINAL MODEL TESTING GROUND------------------\n",
        "#smiles_biased_max, prediction_biased_max = estimate_and_update(my_generator_max, my_predictor, n_to_generate= 100)\n",
        "\n",
        "smiles_biased_max = estimate_and_update(my_generator_max, n_to_generate= 100)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "9NeqfPvHpZz5",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "print(smiles_biased_max[0:5])"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ztepvz0JiatR",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "sns.kdeplot(prediction_biased_max,label='Maximized', shade=True, color='red')\n",
        "sns.kdeplot(prediction_unbiased, label='Unbiased', shade=True, color='grey')\n",
        "plt.xlabel('pIC50 values')\n",
        "plt.show()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "sc_UAgBKhNpN",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#saving array with maximized smiles strings to file data.csv locally \n",
        "from numpy import asarray\n",
        "from numpy import savetxt\n",
        "# define data\n",
        "data = asarray(smiles_biased_max)\n",
        "# save to csv file\n",
        "savetxt('maximimum_biased_generated_molecules.csv', data, delimiter=',', fmt='%s')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "A7CO-w9rjG_U",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#saving array with maximized smiles strings to file data.csv locally \n",
        "from numpy import asarray\n",
        "from numpy import savetxt\n",
        "# define data\n",
        "data = asarray(prediction_biased_max)\n",
        "# save to csv file\n",
        "savetxt('pred.csv', data, delimiter=',', fmt='%s')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "zTXZa0hSL69A",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "my_generator_max.save_model(path = \"gen_model\")"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "cabncJiAVF3W",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "1bZqQz-7h-oB",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from google.colab import files\n",
        "files.download('/content/gen_model') "
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "9kgJqPf3jNrL",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from google.colab import files\n",
        "files.download('/content/pred.csv') "
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}